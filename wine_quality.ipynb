{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b98be796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72811417",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_wine_file_path=r'T:\\TOSHITH\\PROGRAMMING\\Wine-Quality-Classification-using-ML\\winequality-red.csv'\n",
    "white_wine_file_path=r'T:\\TOSHITH\\PROGRAMMING\\Wine-Quality-Classification-using-ML\\winequality-white.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414f2fbb",
   "metadata": {},
   "source": [
    "### step 1 combine data and preprocess it for red and white wine seperately "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66928a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 12) (4898, 12)\n",
      "quality\n",
      "5    681\n",
      "6    638\n",
      "7    199\n",
      "4     53\n",
      "8     18\n",
      "3     10\n",
      "Name: count, dtype: int64\n",
      "quality\n",
      "6    2198\n",
      "5    1457\n",
      "7     880\n",
      "8     175\n",
      "4     163\n",
      "3      20\n",
      "9       5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "red_wine_df=pd.read_csv(red_wine_file_path,sep=';')\n",
    "white_wine_df=pd.read_csv(white_wine_file_path,sep=';')\n",
    "'''\n",
    "#unwanted_qualities = [ 3, 9,8,4]\n",
    "\n",
    "# Filter out those rows from red and white wine data\n",
    "red_wine_df = red_wine_df[~red_wine_df['quality'].isin(unwanted_qualities)]\n",
    "white_wine_df = white_wine_df[~white_wine_df['quality'].isin(unwanted_qualities)]'''\n",
    "\n",
    "print(red_wine_df.shape,white_wine_df.shape)\n",
    "#red_wine_df.head()\n",
    "print(red_wine_df['quality'].value_counts())\n",
    "print(white_wine_df['quality'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c9e3f7",
   "metadata": {},
   "source": [
    "So we see that the data is unbalanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fde6ae56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is this really necessairy as some row values have become negative'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#function to scale our data to make it easier for our model to learn \n",
    "\n",
    "def scaler(wine_df):\n",
    "    columns=list(wine_df.columns)\n",
    "\n",
    "    wine_df=StandardScaler().fit_transform(wine_df)\n",
    "    wine_df=pd.DataFrame(wine_df,columns=columns)\n",
    "    return wine_df\n",
    "\n",
    "'''is this really necessairy as some row values have become negative'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2566c0",
   "metadata": {},
   "source": [
    "### 1. Undersampling\n",
    "* As white is more we will reduce it's numbers to equal reds\n",
    "* Also we will do a train test split before sampling as we dont want to introduce redundant samples in the training and testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d05b4901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1119, 12), (480, 12), (4418, 12), (480, 12))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#70:30 split \n",
    "split_ratio=0.3\n",
    "#the data frame in train and test still contains the quality column so we have garbage values which we will not use\n",
    "\n",
    "red_wine_train, red_wine_test, garbage1,garbage2 = train_test_split(red_wine_df,red_wine_df['quality'],test_size=split_ratio)\n",
    "\n",
    "\n",
    "#we want same no of samples in white wine test as red wine \n",
    "\n",
    "white_wine_test=white_wine_df.sample(n=red_wine_test.shape[0])\n",
    "white_wine_train=white_wine_df.drop(white_wine_test.index)\n",
    "\n",
    "red_wine_train.shape,red_wine_test.shape,white_wine_train.shape, white_wine_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8da596df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red Wine Test Distribution:\n",
      " quality\n",
      "3      4\n",
      "4     22\n",
      "5    198\n",
      "6    191\n",
      "7     59\n",
      "8      6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "White Wine Test Distribution:\n",
      " quality\n",
      "3      4\n",
      "4     22\n",
      "5    198\n",
      "6    191\n",
      "7     59\n",
      "8      6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# here i am trying to get the same record composition in white test as red test \n",
    "# Get red wine test set distribution\n",
    "quality_counts = red_wine_test['quality'].value_counts()\n",
    "\n",
    "# Sample white wine test set with the same quality distribution\n",
    "white_wine_test_list = []\n",
    "\n",
    "for quality, count in quality_counts.items():\n",
    "    subset = white_wine_df[white_wine_df['quality'] == quality]\n",
    "    \n",
    "    # Check if white wine has enough samples for the current quality\n",
    "    if len(subset) < count:\n",
    "        raise ValueError(f\"Not enough white wine samples for quality {quality}\")\n",
    "    \n",
    "    sampled = subset.sample(n=count, random_state=42)\n",
    "    white_wine_test_list.append(sampled)\n",
    "\n",
    "# Combine sampled groups into final white_wine_test\n",
    "white_wine_test = pd.concat(white_wine_test_list)\n",
    "\n",
    "# Drop these from the white_wine_df to get white_wine_train\n",
    "white_wine_train = white_wine_df.drop(white_wine_test.index)\n",
    "\n",
    "# Optional: print distribution comparison\n",
    "print(\"Red Wine Test Distribution:\\n\", red_wine_test['quality'].value_counts().sort_index())\n",
    "print(\"\\nWhite Wine Test Distribution:\\n\", white_wine_test['quality'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f4f57",
   "metadata": {},
   "source": [
    "encoding red as 0 and white as 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae9d1b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_train_and_test(red_wine_tr,white_wine_tr,red_wine_test,white_wine_test):\n",
    "    # Add 'colour' column\n",
    "    red_wine_tr['colour'] = 0\n",
    "    white_wine_tr['colour'] = 1\n",
    "    red_wine_test['colour'] = 0\n",
    "    white_wine_test['colour'] = 1\n",
    "\n",
    "    # Drop 'quality' for X, but keep it for Y\n",
    "    X_train = pd.concat([\n",
    "        red_wine_tr.drop(columns=['quality']),\n",
    "        white_wine_tr.drop(columns=['quality'])\n",
    "    ], axis=0)\n",
    "\n",
    "    Y_train = pd.concat([\n",
    "        red_wine_tr['quality'],\n",
    "        white_wine_tr['quality']\n",
    "    ], axis=0)\n",
    "\n",
    "    X_test = pd.concat([\n",
    "        red_wine_test.drop(columns=['quality']),\n",
    "        white_wine_test.drop(columns=['quality'])\n",
    "    ], axis=0)\n",
    "\n",
    "    Y_test = pd.concat([\n",
    "        red_wine_test['quality'],\n",
    "        white_wine_test['quality']\n",
    "    ], axis=0)\n",
    "\n",
    "    return X_train,X_test,Y_train,Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db49d4ef",
   "metadata": {},
   "source": [
    "US is for under sample , N is for normal with out sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57e8505e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2238, 12), (960, 12), (2238,), (960,), (5537, 12))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need to undersample white \n",
    "no_of_red=red_wine_train.shape[0] #shape of train y\n",
    "\n",
    "N_X_train,N_X_test,N_Y_train,N_Y_test=return_train_and_test(red_wine_train,white_wine_train,red_wine_test,white_wine_test)\n",
    "\n",
    "sample_white= white_wine_train.sample(no_of_red) # we get equal no of columns \n",
    "US_X_train,US_X_test,US_Y_train,US_Y_test=return_train_and_test(red_wine_train,sample_white,red_wine_test,white_wine_test)\n",
    "\n",
    "US_X_train.shape,US_X_test.shape,US_Y_train.shape,US_Y_test.shape,N_X_train.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1444365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>colour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.383219</td>\n",
       "      <td>1.524135</td>\n",
       "      <td>-1.395194</td>\n",
       "      <td>-0.457723</td>\n",
       "      <td>0.593153</td>\n",
       "      <td>-0.605964</td>\n",
       "      <td>-1.193349</td>\n",
       "      <td>0.110145</td>\n",
       "      <td>0.7891</td>\n",
       "      <td>0.166899</td>\n",
       "      <td>0.70689</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0      -0.383219          1.524135    -1.395194       -0.457723   0.593153   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide   density      pH  sulphates  \\\n",
       "0            -0.605964             -1.193349  0.110145  0.7891   0.166899   \n",
       "\n",
       "   alcohol  colour  \n",
       "0  0.70689     0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "US_X_train=scaler(US_X_train)\n",
    "US_X_test=scaler(US_X_test)\n",
    "#as the colour column has changed because of the standard scaler \n",
    "US_X_train['colour'] = US_X_train['colour'].replace(-1, 0)\n",
    "US_X_test['colour'] = US_X_test['colour'].replace(-1, 0)\n",
    "\n",
    "US_X_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c658dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>colour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5532</th>\n",
       "      <td>-0.763330</td>\n",
       "      <td>-0.759210</td>\n",
       "      <td>-0.220608</td>\n",
       "      <td>-0.832715</td>\n",
       "      <td>-0.457760</td>\n",
       "      <td>-0.419812</td>\n",
       "      <td>-0.500299</td>\n",
       "      <td>-1.131484</td>\n",
       "      <td>0.354186</td>\n",
       "      <td>-0.168153</td>\n",
       "      <td>0.571565</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5533</th>\n",
       "      <td>-0.443482</td>\n",
       "      <td>-0.052687</td>\n",
       "      <td>0.275306</td>\n",
       "      <td>0.495264</td>\n",
       "      <td>-0.213124</td>\n",
       "      <td>1.445371</td>\n",
       "      <td>0.886705</td>\n",
       "      <td>0.112275</td>\n",
       "      <td>-0.401426</td>\n",
       "      <td>-0.452991</td>\n",
       "      <td>-0.756327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5534</th>\n",
       "      <td>-0.523444</td>\n",
       "      <td>-0.566522</td>\n",
       "      <td>-0.929057</td>\n",
       "      <td>-0.915713</td>\n",
       "      <td>-0.396601</td>\n",
       "      <td>-0.080688</td>\n",
       "      <td>-0.153548</td>\n",
       "      <td>-0.668382</td>\n",
       "      <td>-1.408907</td>\n",
       "      <td>-0.452991</td>\n",
       "      <td>-0.922313</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5535</th>\n",
       "      <td>-1.323065</td>\n",
       "      <td>-0.245375</td>\n",
       "      <td>-0.149763</td>\n",
       "      <td>-0.936463</td>\n",
       "      <td>-0.977613</td>\n",
       "      <td>-0.645895</td>\n",
       "      <td>-0.171798</td>\n",
       "      <td>-1.941912</td>\n",
       "      <td>0.794959</td>\n",
       "      <td>-1.022667</td>\n",
       "      <td>1.899456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5536</th>\n",
       "      <td>-0.923255</td>\n",
       "      <td>-0.759210</td>\n",
       "      <td>0.416996</td>\n",
       "      <td>-0.998712</td>\n",
       "      <td>-1.038773</td>\n",
       "      <td>-0.532853</td>\n",
       "      <td>-0.390799</td>\n",
       "      <td>-1.703746</td>\n",
       "      <td>0.291218</td>\n",
       "      <td>-1.449924</td>\n",
       "      <td>1.069524</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "5532      -0.763330         -0.759210    -0.220608       -0.832715  -0.457760   \n",
       "5533      -0.443482         -0.052687     0.275306        0.495264  -0.213124   \n",
       "5534      -0.523444         -0.566522    -0.929057       -0.915713  -0.396601   \n",
       "5535      -1.323065         -0.245375    -0.149763       -0.936463  -0.977613   \n",
       "5536      -0.923255         -0.759210     0.416996       -0.998712  -1.038773   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide   density        pH  \\\n",
       "5532            -0.419812             -0.500299 -1.131484  0.354186   \n",
       "5533             1.445371              0.886705  0.112275 -0.401426   \n",
       "5534            -0.080688             -0.153548 -0.668382 -1.408907   \n",
       "5535            -0.645895             -0.171798 -1.941912  0.794959   \n",
       "5536            -0.532853             -0.390799 -1.703746  0.291218   \n",
       "\n",
       "      sulphates   alcohol  colour  \n",
       "5532  -0.168153  0.571565       1  \n",
       "5533  -0.452991 -0.756327       1  \n",
       "5534  -0.452991 -0.922313       1  \n",
       "5535  -1.022667  1.899456       1  \n",
       "5536  -1.449924  1.069524       1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_X_train = scaler(N_X_train)\n",
    "N_X_test = scaler(N_X_test)\n",
    "# as these 2 are unbalenced data ill change the colour column to 0 and 1 manually \n",
    "#can apply this to above as well \n",
    "\n",
    "unique_values = N_X_train['colour'].unique()\n",
    "lower_value = min(unique_values)\n",
    "\n",
    "N_X_train['colour'] = (N_X_train['colour'] != lower_value).astype(int)\n",
    "\n",
    "unique_values = N_X_test['colour'].unique()\n",
    "lower_value = min(unique_values)\n",
    "N_X_test['colour'] = (N_X_test['colour'] != lower_value).astype(int)\n",
    "\n",
    "N_X_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a9d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform train test split before sampling and sampling should be done only on training data \n",
    "\n",
    "#also verify if the data column has the same no of 1 and 0 (y values) values 11:57 in the video \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a5554f",
   "metadata": {},
   "source": [
    "2 upsampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9333784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colour\n",
      "1    4418\n",
      "0    1119\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(N_X_train['colour'].value_counts()) # w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daf5a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index to avoid index misalignment\n",
    "N_X_train = N_X_train.reset_index(drop=True)\n",
    "N_Y_train = N_Y_train.reset_index(drop=True)\n",
    "\n",
    "# Split by colour\n",
    "red_mask = N_X_train['colour'] == 0\n",
    "red_X = N_X_train[red_mask]\n",
    "red_Y = N_Y_train[red_mask]\n",
    "\n",
    "white_mask = N_X_train['colour'] == 1\n",
    "white_X = N_X_train[white_mask]\n",
    "white_Y = N_Y_train[white_mask]\n",
    "\n",
    "# Now you can upsample\n",
    "from sklearn.utils import resample\n",
    "red_X_upsampled, red_Y_upsampled = resample(\n",
    "    red_X, red_Y,\n",
    "    replace=True,\n",
    "    n_samples=len(white_X),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "UP_X_train = pd.concat([red_X_upsampled, white_X])\n",
    "UP_Y_train = pd.concat([red_Y_upsampled, white_Y])\n",
    "UP_X_test = US_X_test.copy()\n",
    "UP_Y_test = US_Y_test.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03106d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colour\n",
      "0    4418\n",
      "1    4418\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(UP_X_train['colour'].value_counts()) # w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3825ba2e",
   "metadata": {},
   "source": [
    "### apply smote "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d96ad858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "183f889e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: Counter({6: 2454, 5: 1742, 7: 961, 8: 181, 4: 172, 3: 22, 9: 5})\n"
     ]
    }
   ],
   "source": [
    "print(\"Original class distribution:\", Counter(N_Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15670da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled class distribution: Counter({6: 2454, 5: 1742, 7: 961, 4: 500, 8: 500, 3: 22, 9: 5})\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "sampling_strategy = {4: 500, 8: 500}\n",
    "smote = SMOTE(sampling_strategy=sampling_strategy, random_state=42)\n",
    "SM_X_train, SM_Y_train = smote.fit_resample(N_X_train, N_Y_train)\n",
    "print(\"Resampled class distribution:\", Counter(SM_Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8de23c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colour\n",
      "1    4986\n",
      "0    1198\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(SM_X_train['colour'].value_counts()) #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2febbf",
   "metadata": {},
   "source": [
    "### use different ML model for the same data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21fee7b",
   "metadata": {},
   "source": [
    "XGBoost classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77f16fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'subsample': 0.8, 'reg_lambda': 0.5, 'reg_alpha': 0.1, 'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.05, 'gamma': 0, 'colsample_bytree': 0.6}\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Encode labels\n",
    "unique_labels = sorted(set(US_Y_train) | set(US_Y_test))\n",
    "le = LabelEncoder()\n",
    "le.fit(unique_labels)\n",
    "\n",
    "US_Y_train_encoded = le.transform(US_Y_train)\n",
    "US_Y_test_encoded = le.transform(US_Y_test)  # optional, in case needed later\n",
    "\n",
    "# Define base model\n",
    "xgb = XGBClassifier(objective='multi:softmax', num_class=len(unique_labels), random_state=42)\n",
    "\n",
    "# Define hyperparameter grid for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 1, 2, 5],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1],\n",
    "    'reg_lambda': [0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "# Perform randomized search\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "random_search.fit(US_X_train, US_Y_train_encoded)\n",
    "\n",
    "# Get best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Predict and decode labels\n",
    "y_pred_encoded = best_model.predict(US_X_test)\n",
    "US_y_pred = le.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c79502d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Get unique labels and encode them\n",
    "unique_labels = sorted(set(N_Y_train) | set(N_Y_test))\n",
    "le = LabelEncoder()\n",
    "le.fit(unique_labels)\n",
    "\n",
    "N_Y_train_encoded = le.transform(N_Y_train)\n",
    "N_Y_test_encoded = le.transform(N_Y_test)\n",
    "\n",
    "model = XGBClassifier(objective='multi:softmax', num_class=len(unique_labels), random_state=42)\n",
    "model.fit(N_X_train, N_Y_train_encoded)\n",
    "\n",
    "y_pred_encoded = model.predict(N_X_test)\n",
    "N_y_pred = le.inverse_transform(y_pred_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ff3ebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Get unique labels and encode them\n",
    "unique_labels = sorted(set(UP_Y_train) | set(UP_Y_test))\n",
    "le = LabelEncoder()\n",
    "le.fit(unique_labels)\n",
    "\n",
    "UP_Y_train_encoded = le.transform(UP_Y_train)\n",
    "UP_Y_test_encoded = le.transform(UP_Y_test)\n",
    "\n",
    "model = XGBClassifier(objective='multi:softmax', num_class=len(unique_labels), random_state=42)\n",
    "model.fit(UP_X_train, UP_Y_train_encoded)\n",
    "\n",
    "y_pred_encoded = model.predict(UP_X_test)\n",
    "UP_y_pred = le.inverse_transform(y_pred_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "984f001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Get unique labels and encode them\n",
    "unique_labels = sorted(set(SM_Y_train) | set(N_Y_test))\n",
    "le = LabelEncoder()\n",
    "le.fit(unique_labels)\n",
    "\n",
    "SM_Y_train_encoded = le.transform(SM_Y_train)\n",
    "\n",
    "model = XGBClassifier(objective='multi:softmax', num_class=len(unique_labels), random_state=42)\n",
    "model.fit(SM_X_train, SM_Y_train_encoded)\n",
    "\n",
    "y_pred_encoded = model.predict(N_X_test)\n",
    "SM_y_pred = le.inverse_transform(y_pred_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8a6181f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Undersampled data: 0.5822916666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.00      0.00      0.00        44\n",
      "           5       0.67      0.64      0.65       396\n",
      "           6       0.54      0.70      0.61       382\n",
      "           7       0.48      0.33      0.39       118\n",
      "           8       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.58       960\n",
      "   macro avg       0.28      0.28      0.28       960\n",
      "weighted avg       0.55      0.58      0.56       960\n",
      "\n",
      "Accuracy for normal data: 0.5010416666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.00      0.00      0.00        44\n",
      "           5       0.59      0.54      0.56       396\n",
      "           6       0.47      0.62      0.53       382\n",
      "           7       0.36      0.27      0.31       118\n",
      "           8       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.50       960\n",
      "   macro avg       0.29      0.25      0.26       960\n",
      "weighted avg       0.48      0.50      0.48       960\n",
      "\n",
      "Accuracy for normal data: 0.5072916666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.00      0.00      0.00        44\n",
      "           5       0.60      0.53      0.56       396\n",
      "           6       0.47      0.64      0.54       382\n",
      "           7       0.39      0.26      0.31       118\n",
      "           8       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.51       960\n",
      "   macro avg       0.30      0.25      0.26       960\n",
      "weighted avg       0.49      0.51      0.49       960\n",
      "\n",
      "Accuracy for normal data: 0.475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.19      0.11      0.14        44\n",
      "           5       0.58      0.49      0.53       396\n",
      "           6       0.46      0.59      0.51       382\n",
      "           7       0.32      0.26      0.29       118\n",
      "           8       0.21      0.25      0.23        12\n",
      "\n",
      "    accuracy                           0.47       960\n",
      "   macro avg       0.29      0.28      0.28       960\n",
      "weighted avg       0.47      0.47      0.47       960\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Undersampled data:\", accuracy_score(US_Y_test, US_y_pred))\n",
    "print(classification_report(US_Y_test, US_y_pred))\n",
    "print(\"Accuracy for normal data:\", accuracy_score(N_Y_test, N_y_pred))\n",
    "print(classification_report(N_Y_test, N_y_pred))\n",
    "print(\"Accuracy for normal data:\", accuracy_score(UP_Y_test, UP_y_pred))\n",
    "print(classification_report(UP_Y_test, UP_y_pred))\n",
    "\n",
    "print(\"Accuracy for normal data:\", accuracy_score(N_Y_test, SM_y_pred))\n",
    "print(classification_report(N_Y_test, SM_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c07a1ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💡 Cross-Validation on TRAINING Set:\n",
      "Scores: [0.609375   0.61607143 0.640625   0.55257271 0.56823266]\n",
      "Mean Accuracy: 0.5974\n",
      "Standard Deviation: 0.0323\n",
      "\n",
      "🧪 Evaluation on TEST Set:\n",
      "Accuracy: 0.5822916666666667\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.00      0.00      0.00        44\n",
      "           5       0.67      0.64      0.65       396\n",
      "           6       0.54      0.70      0.61       382\n",
      "           7       0.48      0.33      0.39       118\n",
      "           8       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.58       960\n",
      "   macro avg       0.28      0.28      0.28       960\n",
      "weighted avg       0.55      0.58      0.56       960\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# 1️⃣ Cross-validation on TRAINING data\n",
    "train_cv_scores = cross_val_score(\n",
    "    best_model,\n",
    "    US_X_train,\n",
    "    US_Y_train_encoded,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\n💡 Cross-Validation on TRAINING Set:\")\n",
    "print(f\"Scores: {train_cv_scores}\")\n",
    "print(f\"Mean Accuracy: {np.mean(train_cv_scores):.4f}\")\n",
    "print(f\"Standard Deviation: {np.std(train_cv_scores):.4f}\")\n",
    "\n",
    "# 2️⃣ Evaluation on TEST data\n",
    "y_test_pred_encoded = best_model.predict(US_X_test)\n",
    "y_test_pred = le.inverse_transform(y_test_pred_encoded)\n",
    "\n",
    "print(\"\\n🧪 Evaluation on TEST Set:\")\n",
    "print(\"Accuracy:\", accuracy_score(US_Y_test, y_test_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(US_Y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70379dc",
   "metadata": {},
   "source": [
    "### random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c325282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f2d848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "US_Y_train_encoded = le.fit_transform(US_Y_train)\n",
    "US_Y_test_encoded = le.transform(US_Y_test)\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(US_X_train, US_Y_train_encoded)\n",
    "y_pred_encoded = rf_classifier.predict(US_X_test)\n",
    "US_y_pred = le.inverse_transform(y_pred_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b490632",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Y_train_encoded = le.fit_transform(N_Y_train)\n",
    "N_Y_test_encoded = le.transform(N_Y_test)\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(N_X_train, N_Y_train_encoded)\n",
    "y_pred_encoded = rf_classifier.predict(N_X_test)\n",
    "N_y_pred = le.inverse_transform(y_pred_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7839d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Undersampled data: 0.6229166666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.50      0.02      0.04        44\n",
      "           5       0.73      0.68      0.70       396\n",
      "           6       0.56      0.75      0.64       382\n",
      "           7       0.52      0.36      0.42       118\n",
      "           8       1.00      0.08      0.15        12\n",
      "\n",
      "    accuracy                           0.62       960\n",
      "   macro avg       0.55      0.31      0.33       960\n",
      "weighted avg       0.62      0.62      0.60       960\n",
      "\n",
      "Accuracy for normal data: 0.5197916666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.00      0.00      0.00        44\n",
      "           5       0.64      0.53      0.58       396\n",
      "           6       0.47      0.70      0.57       382\n",
      "           7       0.34      0.19      0.25       118\n",
      "           8       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.52       960\n",
      "   macro avg       0.24      0.24      0.23       960\n",
      "weighted avg       0.49      0.52      0.49       960\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Undersampled data:\", accuracy_score(US_Y_test, US_y_pred))\n",
    "print(classification_report(US_Y_test, US_y_pred))\n",
    "print(\"Accuracy for normal data:\", accuracy_score(N_Y_test, N_y_pred))\n",
    "print(classification_report(N_Y_test, N_y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
