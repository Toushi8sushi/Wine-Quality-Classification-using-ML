{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b98be796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "72811417",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_wine_file_path=r'T:\\TOSHITH\\PROGRAMMING\\Wine-Quality-Classification-using-ML\\winequality-red.csv'\n",
    "white_wine_file_path=r'T:\\TOSHITH\\PROGRAMMING\\Wine-Quality-Classification-using-ML\\winequality-white.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414f2fbb",
   "metadata": {},
   "source": [
    "### step 1 combine data and preprocess it for red and white wine seperately "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "66928a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1518, 12) (4535, 12)\n",
      "quality\n",
      "5    681\n",
      "6    638\n",
      "7    199\n",
      "Name: count, dtype: int64\n",
      "quality\n",
      "6    2198\n",
      "5    1457\n",
      "7     880\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "red_wine_df=pd.read_csv(red_wine_file_path,sep=';')\n",
    "white_wine_df=pd.read_csv(white_wine_file_path,sep=';')\n",
    "\n",
    "unwanted_qualities = [ 3,9,8,4]\n",
    "\n",
    "# Filter out those rows from red and white wine data\n",
    "red_wine_df = red_wine_df[~red_wine_df['quality'].isin(unwanted_qualities)]\n",
    "white_wine_df = white_wine_df[~white_wine_df['quality'].isin(unwanted_qualities)]\n",
    "\n",
    "print(red_wine_df.shape,white_wine_df.shape)\n",
    "#red_wine_df.head()\n",
    "print(red_wine_df['quality'].value_counts())\n",
    "print(white_wine_df['quality'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c9e3f7",
   "metadata": {},
   "source": [
    "So we see that the data is unbalanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fde6ae56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is this really necessairy as some row values have become negative'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#function to scale our data to make it easier for our model to learn \n",
    "\n",
    "def scaler(wine_df):\n",
    "    columns=list(wine_df.columns)\n",
    "\n",
    "    wine_df=StandardScaler().fit_transform(wine_df)\n",
    "    wine_df=pd.DataFrame(wine_df,columns=columns)\n",
    "    return wine_df\n",
    "\n",
    "'''is this really necessairy as some row values have become negative'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2566c0",
   "metadata": {},
   "source": [
    "### 1. Undersampling\n",
    "* As white is more we will reduce it's numbers to equal reds\n",
    "* Also we will do a train test split before sampling as we dont want to introduce redundant samples in the training and testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d05b4901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1214, 12), (304, 12), (4231, 12), (304, 12))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#70:30 split \n",
    "split_ratio=0.2\n",
    "#the data frame in train and test still contains the quality column so we have garbage values which we will not use\n",
    "\n",
    "red_wine_train, red_wine_test, garbage1,garbage2 = train_test_split(red_wine_df,red_wine_df['quality'],test_size=split_ratio)\n",
    "\n",
    "\n",
    "#we want same no of samples in white wine test as red wine \n",
    "\n",
    "white_wine_test=white_wine_df.sample(n=red_wine_test.shape[0])\n",
    "white_wine_train=white_wine_df.drop(white_wine_test.index)\n",
    "\n",
    "red_wine_train.shape,red_wine_test.shape,white_wine_train.shape, white_wine_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8da596df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red Wine Test Distribution:\n",
      " quality\n",
      "5    126\n",
      "6    138\n",
      "7     40\n",
      "Name: count, dtype: int64\n",
      "\n",
      "White Wine Test Distribution:\n",
      " quality\n",
      "5    126\n",
      "6    138\n",
      "7     40\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# here i am trying to get the same record composition in white test as red test \n",
    "# Get red wine test set distribution\n",
    "quality_counts = red_wine_test['quality'].value_counts()\n",
    "\n",
    "# Sample white wine test set with the same quality distribution\n",
    "white_wine_test_list = []\n",
    "\n",
    "for quality, count in quality_counts.items():\n",
    "    subset = white_wine_df[white_wine_df['quality'] == quality]\n",
    "    \n",
    "    # Check if white wine has enough samples for the current quality\n",
    "    if len(subset) < count:\n",
    "        raise ValueError(f\"Not enough white wine samples for quality {quality}\")\n",
    "    \n",
    "    sampled = subset.sample(n=count, random_state=42)\n",
    "    white_wine_test_list.append(sampled)\n",
    "\n",
    "# Combine sampled groups into final white_wine_test\n",
    "white_wine_test = pd.concat(white_wine_test_list)\n",
    "\n",
    "# Drop these from the white_wine_df to get white_wine_train\n",
    "white_wine_train = white_wine_df.drop(white_wine_test.index)\n",
    "\n",
    "# Optional: print distribution comparison\n",
    "print(\"Red Wine Test Distribution:\\n\", red_wine_test['quality'].value_counts().sort_index())\n",
    "print(\"\\nWhite Wine Test Distribution:\\n\", white_wine_test['quality'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f4f57",
   "metadata": {},
   "source": [
    "encoding red as 0 and white as 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ae9d1b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_train_and_test(red_wine_tr,white_wine_tr,red_wine_test,white_wine_test):\n",
    "    # Add 'colour' column\n",
    "    red_wine_tr['colour'] = 0\n",
    "    white_wine_tr['colour'] = 1\n",
    "    red_wine_test['colour'] = 0\n",
    "    white_wine_test['colour'] = 1\n",
    "\n",
    "    # Drop 'quality' for X, but keep it for Y\n",
    "    X_train = pd.concat([\n",
    "        red_wine_tr.drop(columns=['quality']),\n",
    "        white_wine_tr.drop(columns=['quality'])\n",
    "    ], axis=0)\n",
    "\n",
    "    Y_train = pd.concat([\n",
    "        red_wine_tr['quality'],\n",
    "        white_wine_tr['quality']\n",
    "    ], axis=0)\n",
    "\n",
    "    X_test = pd.concat([\n",
    "        red_wine_test.drop(columns=['quality']),\n",
    "        white_wine_test.drop(columns=['quality'])\n",
    "    ], axis=0)\n",
    "\n",
    "    Y_test = pd.concat([\n",
    "        red_wine_test['quality'],\n",
    "        white_wine_test['quality']\n",
    "    ], axis=0)\n",
    "\n",
    "    return X_train,X_test,Y_train,Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db49d4ef",
   "metadata": {},
   "source": [
    "US is for under sample , N is for normal with out sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "57e8505e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2428, 12), (608, 12), (2428,), (608,), (5445, 12))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need to undersample white \n",
    "no_of_red=red_wine_train.shape[0] #shape of train y\n",
    "\n",
    "N_X_train,N_X_test,N_Y_train,N_Y_test=return_train_and_test(red_wine_train,white_wine_train,red_wine_test,white_wine_test)\n",
    "\n",
    "sample_white= white_wine_train.sample(no_of_red) # we get equal no of columns \n",
    "US_X_train,US_X_test,US_Y_train,US_Y_test=return_train_and_test(red_wine_train,sample_white,red_wine_test,white_wine_test)\n",
    "\n",
    "US_X_train.shape,US_X_test.shape,US_Y_train.shape,US_Y_test.shape,N_X_train.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b1444365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>colour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.237691</td>\n",
       "      <td>1.816766</td>\n",
       "      <td>-1.243898</td>\n",
       "      <td>-0.555151</td>\n",
       "      <td>0.286952</td>\n",
       "      <td>-1.190181</td>\n",
       "      <td>-1.035899</td>\n",
       "      <td>1.053522</td>\n",
       "      <td>-0.114163</td>\n",
       "      <td>-0.078668</td>\n",
       "      <td>-0.293464</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0       1.237691          1.816766    -1.243898       -0.555151   0.286952   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide   density        pH  sulphates  \\\n",
       "0            -1.190181             -1.035899  1.053522 -0.114163  -0.078668   \n",
       "\n",
       "    alcohol  colour  \n",
       "0 -0.293464     0.0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "US_X_train=scaler(US_X_train)\n",
    "US_X_test=scaler(US_X_test)\n",
    "#as the colour column has changed because of the standard scaler \n",
    "US_X_train['colour'] = US_X_train['colour'].replace(-1, 0)\n",
    "US_X_test['colour'] = US_X_test['colour'].replace(-1, 0)\n",
    "\n",
    "US_X_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1c658dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>colour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>-0.777132</td>\n",
       "      <td>-0.770468</td>\n",
       "      <td>-0.219238</td>\n",
       "      <td>-0.827536</td>\n",
       "      <td>-0.472392</td>\n",
       "      <td>-0.425822</td>\n",
       "      <td>-0.476053</td>\n",
       "      <td>-1.176364</td>\n",
       "      <td>0.343964</td>\n",
       "      <td>-0.198533</td>\n",
       "      <td>0.611650</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5441</th>\n",
       "      <td>-0.458883</td>\n",
       "      <td>-0.058847</td>\n",
       "      <td>0.272451</td>\n",
       "      <td>0.493528</td>\n",
       "      <td>-0.239495</td>\n",
       "      <td>1.509376</td>\n",
       "      <td>0.898198</td>\n",
       "      <td>0.072923</td>\n",
       "      <td>-0.410420</td>\n",
       "      <td>-0.474883</td>\n",
       "      <td>-0.738428</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5442</th>\n",
       "      <td>-0.538445</td>\n",
       "      <td>-0.576390</td>\n",
       "      <td>-0.921650</td>\n",
       "      <td>-0.910102</td>\n",
       "      <td>-0.414167</td>\n",
       "      <td>-0.073968</td>\n",
       "      <td>-0.132490</td>\n",
       "      <td>-0.711204</td>\n",
       "      <td>-1.416266</td>\n",
       "      <td>-0.474883</td>\n",
       "      <td>-0.907187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5443</th>\n",
       "      <td>-1.334068</td>\n",
       "      <td>-0.252926</td>\n",
       "      <td>-0.148996</td>\n",
       "      <td>-0.930744</td>\n",
       "      <td>-0.967298</td>\n",
       "      <td>-0.660392</td>\n",
       "      <td>-0.150573</td>\n",
       "      <td>-1.990394</td>\n",
       "      <td>0.784022</td>\n",
       "      <td>-1.027583</td>\n",
       "      <td>1.961727</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5444</th>\n",
       "      <td>-0.936257</td>\n",
       "      <td>-0.770468</td>\n",
       "      <td>0.412933</td>\n",
       "      <td>-0.992669</td>\n",
       "      <td>-1.025522</td>\n",
       "      <td>-0.543107</td>\n",
       "      <td>-0.367560</td>\n",
       "      <td>-1.751168</td>\n",
       "      <td>0.281099</td>\n",
       "      <td>-1.442109</td>\n",
       "      <td>1.117929</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "5440      -0.777132         -0.770468    -0.219238       -0.827536  -0.472392   \n",
       "5441      -0.458883         -0.058847     0.272451        0.493528  -0.239495   \n",
       "5442      -0.538445         -0.576390    -0.921650       -0.910102  -0.414167   \n",
       "5443      -1.334068         -0.252926    -0.148996       -0.930744  -0.967298   \n",
       "5444      -0.936257         -0.770468     0.412933       -0.992669  -1.025522   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide   density        pH  \\\n",
       "5440            -0.425822             -0.476053 -1.176364  0.343964   \n",
       "5441             1.509376              0.898198  0.072923 -0.410420   \n",
       "5442            -0.073968             -0.132490 -0.711204 -1.416266   \n",
       "5443            -0.660392             -0.150573 -1.990394  0.784022   \n",
       "5444            -0.543107             -0.367560 -1.751168  0.281099   \n",
       "\n",
       "      sulphates   alcohol  colour  \n",
       "5440  -0.198533  0.611650       1  \n",
       "5441  -0.474883 -0.738428       1  \n",
       "5442  -0.474883 -0.907187       1  \n",
       "5443  -1.027583  1.961727       1  \n",
       "5444  -1.442109  1.117929       1  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_X_train = scaler(N_X_train)\n",
    "N_X_test = scaler(N_X_test)\n",
    "# as these 2 are unbalenced data ill change the colour column to 0 and 1 manually \n",
    "#can apply this to above as well \n",
    "\n",
    "unique_values = N_X_train['colour'].unique()\n",
    "lower_value = min(unique_values)\n",
    "\n",
    "N_X_train['colour'] = (N_X_train['colour'] != lower_value).astype(int)\n",
    "\n",
    "unique_values = N_X_test['colour'].unique()\n",
    "lower_value = min(unique_values)\n",
    "N_X_test['colour'] = (N_X_test['colour'] != lower_value).astype(int)\n",
    "\n",
    "N_X_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "04a9d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform train test split before sampling and sampling should be done only on training data \n",
    "\n",
    "#also verify if the data column has the same no of 1 and 0 (y values) values 11:57 in the video \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a5554f",
   "metadata": {},
   "source": [
    "2 upsampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d9333784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colour\n",
      "1    4231\n",
      "0    1214\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(N_X_train['colour'].value_counts()) # w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "daf5a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index to avoid index misalignment\n",
    "N_X_train = N_X_train.reset_index(drop=True)\n",
    "N_Y_train = N_Y_train.reset_index(drop=True)\n",
    "\n",
    "# Split by colour\n",
    "red_mask = N_X_train['colour'] == 0\n",
    "red_X = N_X_train[red_mask]\n",
    "red_Y = N_Y_train[red_mask]\n",
    "\n",
    "white_mask = N_X_train['colour'] == 1\n",
    "white_X = N_X_train[white_mask]\n",
    "white_Y = N_Y_train[white_mask]\n",
    "\n",
    "# Now you can upsample\n",
    "from sklearn.utils import resample\n",
    "red_X_upsampled, red_Y_upsampled = resample(\n",
    "    red_X, red_Y,\n",
    "    replace=True,\n",
    "    n_samples=len(white_X),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "UP_X_train = pd.concat([red_X_upsampled, white_X])\n",
    "UP_Y_train = pd.concat([red_Y_upsampled, white_Y])\n",
    "UP_X_test = US_X_test.copy()\n",
    "UP_Y_test = US_Y_test.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "03106d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colour\n",
      "0    4231\n",
      "1    4231\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(UP_X_train['colour'].value_counts()) # w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3825ba2e",
   "metadata": {},
   "source": [
    "### apply smote "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d96ad858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "183f889e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: Counter({6: 2560, 5: 1886, 7: 999})\n"
     ]
    }
   ],
   "source": [
    "print(\"Original class distribution:\", Counter(N_Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "15670da3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The {8, 4} target class is/are not present in the data.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[91]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m sampling_strategy = {\u001b[32m4\u001b[39m: \u001b[32m500\u001b[39m, \u001b[32m8\u001b[39m: \u001b[32m500\u001b[39m}\n\u001b[32m      3\u001b[39m smote = SMOTE(sampling_strategy=sampling_strategy, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m SM_X_train, SM_Y_train = \u001b[43msmote\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN_X_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_Y_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mResampled class distribution:\u001b[39m\u001b[33m\"\u001b[39m, Counter(SM_Y_train))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\base.py:202\u001b[39m, in \u001b[36mBaseSampler.fit_resample\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mfit_resample\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, **params):\n\u001b[32m    182\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[32m    183\u001b[39m \n\u001b[32m    184\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    200\u001b[39m \u001b[33;03m        The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\base.py:101\u001b[39m, in \u001b[36mSamplerMixin.fit_resample\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m     98\u001b[39m arrays_transformer = ArraysTransformer(X, y)\n\u001b[32m     99\u001b[39m X, y, binarize_y = \u001b[38;5;28mself\u001b[39m._check_X_y(X, y)\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m \u001b[38;5;28mself\u001b[39m.sampling_strategy_ = \u001b[43mcheck_sampling_strategy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msampling_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sampling_type\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m output = \u001b[38;5;28mself\u001b[39m._fit_resample(X, y, **params)\n\u001b[32m    107\u001b[39m y_ = (\n\u001b[32m    108\u001b[39m     label_binarize(output[\u001b[32m1\u001b[39m], classes=np.unique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[32m1\u001b[39m]\n\u001b[32m    109\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\utils\\_validation.py:557\u001b[39m, in \u001b[36mcheck_sampling_strategy\u001b[39m\u001b[34m(sampling_strategy, y, sampling_type, **kwargs)\u001b[39m\n\u001b[32m    552\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m OrderedDict(\n\u001b[32m    553\u001b[39m         \u001b[38;5;28msorted\u001b[39m(SAMPLING_TARGET_KIND[sampling_strategy](y, sampling_type).items())\n\u001b[32m    554\u001b[39m     )\n\u001b[32m    555\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sampling_strategy, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    556\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m OrderedDict(\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m         \u001b[38;5;28msorted\u001b[39m(\u001b[43m_sampling_strategy_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampling_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_type\u001b[49m\u001b[43m)\u001b[49m.items())\n\u001b[32m    558\u001b[39m     )\n\u001b[32m    559\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sampling_strategy, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    560\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m OrderedDict(\n\u001b[32m    561\u001b[39m         \u001b[38;5;28msorted\u001b[39m(_sampling_strategy_list(sampling_strategy, y, sampling_type).items())\n\u001b[32m    562\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\utils\\_validation.py:319\u001b[39m, in \u001b[36m_sampling_strategy_dict\u001b[39m\u001b[34m(sampling_strategy, y, sampling_type)\u001b[39m\n\u001b[32m    315\u001b[39m set_diff_sampling_strategy_target = \u001b[38;5;28mset\u001b[39m(sampling_strategy.keys()) - \u001b[38;5;28mset\u001b[39m(\n\u001b[32m    316\u001b[39m     target_stats.keys()\n\u001b[32m    317\u001b[39m )\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(set_diff_sampling_strategy_target) > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    320\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mset_diff_sampling_strategy_target\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m target class is/are not \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpresent in the data.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m     )\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# check that there is no negative number\u001b[39;00m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(n_samples < \u001b[32m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n_samples \u001b[38;5;129;01min\u001b[39;00m sampling_strategy.values()):\n",
      "\u001b[31mValueError\u001b[39m: The {8, 4} target class is/are not present in the data."
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "sampling_strategy = {4: 500, 8: 500}\n",
    "smote = SMOTE(sampling_strategy=sampling_strategy, random_state=42)\n",
    "SM_X_train, SM_Y_train = smote.fit_resample(N_X_train, N_Y_train)\n",
    "print(\"Resampled class distribution:\", Counter(SM_Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de23c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colour\n",
      "1    4947\n",
      "0    1207\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(SM_X_train['colour'].value_counts()) #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586013f5",
   "metadata": {},
   "source": [
    "### apply ensamble technique on your data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2febbf",
   "metadata": {},
   "source": [
    "### use different ML model for the same data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21fee7b",
   "metadata": {},
   "source": [
    "XGBoost classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "77f16fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Hyperparameters: {'subsample': 0.6, 'reg_lambda': 0.1, 'reg_alpha': 0.5, 'n_estimators': 100, 'max_depth': 9, 'learning_rate': 0.2, 'gamma': 0, 'colsample_bytree': 0.8}\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "# Encode labels\n",
    "unique_labels = sorted(set(US_Y_train) | set(US_Y_test))\n",
    "le = LabelEncoder()\n",
    "le.fit(unique_labels)\n",
    "\n",
    "US_Y_train_encoded = le.transform(US_Y_train)\n",
    "US_Y_test_encoded = le.transform(US_Y_test)  # optional, in case needed later\n",
    "\n",
    "\n",
    "# Compute sample weights based on class frequencies\n",
    "sample_weights = compute_sample_weight(class_weight='balanced', y=US_Y_train_encoded)\n",
    "\n",
    "# Define base model\n",
    "xgb = XGBClassifier(objective='multi:softmax', num_class=len(unique_labels), random_state=42)\n",
    "\n",
    "# Define hyperparameter grid for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 1, 2, 5],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1],\n",
    "    'reg_lambda': [0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "# Perform randomized search\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring='f1_weighted', ## changed for getting better f1 score using weighted classes \n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit with sample weights\n",
    "random_search.fit(US_X_train, US_Y_train_encoded, sample_weight=sample_weights)\n",
    "\n",
    "# Get best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Predict and decode labels\n",
    "y_pred_encoded = best_model.predict(US_X_test)\n",
    "US_y_pred = le.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c79502d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "unique_labels = sorted(set(N_Y_train) | set(N_Y_test))\n",
    "le = LabelEncoder()\n",
    "le.fit(unique_labels)\n",
    "\n",
    "N_Y_train_encoded = le.transform(N_Y_train)\n",
    "N_Y_test_encoded = le.transform(N_Y_test)\n",
    "\n",
    "# Compute class-balanced weights\n",
    "sample_weights_N = compute_sample_weight(class_weight='balanced', y=N_Y_train_encoded)\n",
    "\n",
    "# Initialize and fit model with weights\n",
    "model = XGBClassifier(objective='multi:softmax', num_class=len(unique_labels), random_state=42)\n",
    "model.fit(N_X_train, N_Y_train_encoded, sample_weight=sample_weights_N)\n",
    "\n",
    "# Predict and decode labels\n",
    "y_pred_encoded = model.predict(N_X_test)\n",
    "N_y_pred = le.inverse_transform(y_pred_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8ff3ebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "unique_labels = sorted(set(UP_Y_train) | set(UP_Y_test))\n",
    "le = LabelEncoder()\n",
    "le.fit(unique_labels)\n",
    "\n",
    "UP_Y_train_encoded = le.transform(UP_Y_train)\n",
    "UP_Y_test_encoded = le.transform(UP_Y_test)\n",
    "\n",
    "# Compute class-balanced sample weights\n",
    "sample_weights_UP = compute_sample_weight(class_weight='balanced', y=UP_Y_train_encoded)\n",
    "\n",
    "# Initialize model\n",
    "model = XGBClassifier(objective='multi:softmax', num_class=len(unique_labels), random_state=42)\n",
    "\n",
    "# Fit with sample weights\n",
    "model.fit(UP_X_train, UP_Y_train_encoded, sample_weight=sample_weights_UP)\n",
    "\n",
    "# Predict and decode labels\n",
    "y_pred_encoded = model.predict(UP_X_test)\n",
    "UP_y_pred = le.inverse_transform(y_pred_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "984f001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique labels and encode them\n",
    "unique_labels = sorted(set(SM_Y_train) | set(N_Y_test))\n",
    "le = LabelEncoder()\n",
    "le.fit(unique_labels)\n",
    "\n",
    "SM_Y_train_encoded = le.transform(SM_Y_train)\n",
    "N_Y_test_encoded = le.transform(N_Y_test)\n",
    "\n",
    "# Compute sample weights for SM_Y_train\n",
    "sample_weights_SM = compute_sample_weight(class_weight='balanced', y=SM_Y_train_encoded)\n",
    "\n",
    "# Initialize and train model with weights\n",
    "model = XGBClassifier(objective='multi:softmax', num_class=len(unique_labels), random_state=42)\n",
    "model.fit(SM_X_train, SM_Y_train_encoded, sample_weight=sample_weights_SM)\n",
    "\n",
    "# Predict and decode\n",
    "y_pred_encoded = model.predict(N_X_test)\n",
    "SM_y_pred = le.inverse_transform(y_pred_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d8a6181f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Undersampled data: 0.6430921052631579\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           5       0.74      0.63      0.68       252\n",
      "           6       0.61      0.69      0.65       276\n",
      "           7       0.52      0.50      0.51        80\n",
      "\n",
      "    accuracy                           0.64       608\n",
      "   macro avg       0.62      0.61      0.61       608\n",
      "weighted avg       0.65      0.64      0.64       608\n",
      "\n",
      "Accuracy for normal data: 0.5707236842105263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           5       0.67      0.60      0.63       252\n",
      "           6       0.56      0.59      0.57       276\n",
      "           7       0.38      0.44      0.41        80\n",
      "\n",
      "    accuracy                           0.57       608\n",
      "   macro avg       0.53      0.54      0.54       608\n",
      "weighted avg       0.58      0.57      0.57       608\n",
      "\n",
      "Accuracy for normal data: 0.5394736842105263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           5       0.66      0.55      0.60       252\n",
      "           6       0.52      0.58      0.55       276\n",
      "           7       0.33      0.36      0.35        80\n",
      "\n",
      "    accuracy                           0.54       608\n",
      "   macro avg       0.50      0.50      0.50       608\n",
      "weighted avg       0.55      0.54      0.54       608\n",
      "\n",
      "Accuracy for normal data: 0.49506578947368424\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.65      0.47      0.55       252\n",
      "           6       0.52      0.55      0.54       276\n",
      "           7       0.40      0.39      0.39        80\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50       608\n",
      "   macro avg       0.26      0.23      0.25       608\n",
      "weighted avg       0.56      0.50      0.52       608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Undersampled data:\", accuracy_score(US_Y_test, US_y_pred))\n",
    "print(classification_report(US_Y_test, US_y_pred))\n",
    "print(\"Accuracy for normal data:\", accuracy_score(N_Y_test, N_y_pred))\n",
    "print(classification_report(N_Y_test, N_y_pred))\n",
    "print(\"Accuracy for normal data:\", accuracy_score(UP_Y_test, UP_y_pred))\n",
    "print(classification_report(UP_Y_test, UP_y_pred))\n",
    "\n",
    "print(\"Accuracy for normal data:\", accuracy_score(N_Y_test, SM_y_pred))\n",
    "print(classification_report(N_Y_test, SM_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c07a1ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💡 Cross-Validation on TRAINING Set:\n",
      "Scores: [0.66255144 0.64814815 0.61728395 0.59175258 0.60206186]\n",
      "Mean Accuracy: 0.6244\n",
      "Standard Deviation: 0.0270\n",
      "\n",
      "🧪 Evaluation on TEST Set:\n",
      "Accuracy: 0.009868421052631578\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.08      0.02      0.04       252\n",
      "           6       0.00      0.00      0.00       276\n",
      "           7       0.00      0.00      0.00        80\n",
      "\n",
      "    accuracy                           0.01       608\n",
      "   macro avg       0.02      0.00      0.01       608\n",
      "weighted avg       0.03      0.01      0.02       608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\toshi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# 1️⃣ Cross-validation on TRAINING data\n",
    "train_cv_scores = cross_val_score(\n",
    "    best_model,\n",
    "    US_X_train,\n",
    "    US_Y_train_encoded,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\n💡 Cross-Validation on TRAINING Set:\")\n",
    "print(f\"Scores: {train_cv_scores}\")\n",
    "print(f\"Mean Accuracy: {np.mean(train_cv_scores):.4f}\")\n",
    "print(f\"Standard Deviation: {np.std(train_cv_scores):.4f}\")\n",
    "\n",
    "# 2️⃣ Evaluation on TEST data\n",
    "y_test_pred_encoded = best_model.predict(US_X_test)\n",
    "y_test_pred = le.inverse_transform(y_test_pred_encoded)\n",
    "\n",
    "print(\"\\n🧪 Evaluation on TEST Set:\")\n",
    "print(\"Accuracy:\", accuracy_score(US_Y_test, y_test_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(US_Y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70379dc",
   "metadata": {},
   "source": [
    "### random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8c325282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6f2d848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "US_Y_train_encoded = le.fit_transform(US_Y_train)\n",
    "US_Y_test_encoded = le.transform(US_Y_test)\n",
    "rf_classifier = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    scoring='f1_weighted',\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(US_X_train, US_Y_train_encoded)\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "y_pred_encoded = best_rf.predict(US_X_test)\n",
    "US_y_pred = le.inverse_transform(y_pred_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9b490632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Use class_weight='balanced' in base model\n",
    "base_rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Random search with F1 optimization\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=base_rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring='f1_weighted',\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit on encoded training data\n",
    "random_search.fit(N_X_train, N_Y_train_encoded)\n",
    "\n",
    "# Get best model\n",
    "best_rf_model = random_search.best_estimator_\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_encoded = best_rf_model.predict(N_X_test)\n",
    "N_y_pred = le.inverse_transform(y_pred_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "05873bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    }
   ],
   "source": [
    "# Label encoding\n",
    "le = LabelEncoder()\n",
    "UP_Y_train_encoded = le.fit_transform(UP_Y_train)\n",
    "UP_Y_test_encoded = le.transform(UP_Y_test)\n",
    "\n",
    "# Define hyperparameter space\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Base Random Forest model with class weighting\n",
    "rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Randomized search with F1 score optimization\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring='f1_weighted',\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "random_search.fit(UP_X_train, UP_Y_train_encoded)\n",
    "\n",
    "# Get the best model from search\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_encoded = best_rf.predict(UP_X_test)\n",
    "UP_y_pred = le.inverse_transform(y_pred_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e7839d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Undersampled data: 0.6611842105263158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           5       0.76      0.63      0.69       252\n",
      "           6       0.61      0.74      0.67       276\n",
      "           7       0.61      0.46      0.52        80\n",
      "\n",
      "    accuracy                           0.66       608\n",
      "   macro avg       0.66      0.61      0.63       608\n",
      "weighted avg       0.67      0.66      0.66       608\n",
      "\n",
      "Accuracy for normal data: 0.5542763157894737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           5       0.67      0.58      0.62       252\n",
      "           6       0.52      0.59      0.55       276\n",
      "           7       0.36      0.36      0.36        80\n",
      "\n",
      "    accuracy                           0.55       608\n",
      "   macro avg       0.52      0.51      0.51       608\n",
      "weighted avg       0.56      0.55      0.56       608\n",
      "\n",
      "Accuracy for UPsampled data: 0.5575657894736842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           5       0.68      0.52      0.59       252\n",
      "           6       0.52      0.71      0.60       276\n",
      "           7       0.34      0.16      0.22        80\n",
      "\n",
      "    accuracy                           0.56       608\n",
      "   macro avg       0.51      0.46      0.47       608\n",
      "weighted avg       0.56      0.56      0.54       608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Undersampled data:\", accuracy_score(US_Y_test, US_y_pred))\n",
    "print(classification_report(US_Y_test, US_y_pred))\n",
    "\n",
    "print(\"Accuracy for normal data:\", accuracy_score(N_Y_test, N_y_pred))\n",
    "print(classification_report(N_Y_test, N_y_pred))\n",
    "\n",
    "print(\"Accuracy for UPsampled data:\", accuracy_score(UP_Y_test, UP_y_pred))\n",
    "print(classification_report(UP_Y_test, UP_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5e67483c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA94AAAJOCAYAAABBfN/cAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAfhxJREFUeJzs3XlYVGXjxvF7UAFFQFwQFxQXchfcU3NJSTTfXHMvFbeyXElKyyW0xNcSlzDNyq0yNXtTS3OJ0spdcU9zFytxTUksQZjfH/6cnFgS63hG5vu5rrmCM88M95wU555zzvNYrFarVQAAAAAAwBAuZgcAAAAAACAno3gDAAAAAGAgijcAAAAAAAaieAMAAAAAYCCKNwAAAAAABqJ4AwAAAABgIIo3AAAAAAAGongDAAAAAGAgijcAAAAAAAaieAMAAAAAYCCKNwDggTJ//nxZLJYMbyNHjjTkZ27evFmvvvqqrly5Ysjz/xO398fOnTvNjnLP3n77bc2fP9/sGAAAGCa32QEAALgX48ePV5kyZey2Va1a1ZCftXnzZkVGRqp3794qUKCAIT/Dmb399tsqXLiwevfubXYUAAAMQfEGADyQWrVqpdq1a5sd4x9JSkqSh4eH2TFMc/36deXLl8/sGAAAGI5TzQEAOdKXX36pRo0aycPDQ56enmrdurUOHjxoN2bfvn3q3bu3ypYtK3d3d/n5+alPnz66dOmSbcyrr76qiIgISVKZMmVsp7WfOnVKp06dksViyfA0aYvFoldffdXueSwWi3744Qd1795dPj4+euSRR2z3f/jhh6pVq5by5s2rggULqmvXrjpz5sw9vfbevXsrf/78io+P13/+8x/lz59fJUqU0MyZMyVJ+/fvV7NmzeTh4aHSpUtr0aJFdo+/ffr6t99+q2eeeUaFChWSl5eXevbsqV9//TXdz3v77bdVpUoVubm5qXjx4nr++efTnZbftGlTVa1aVbt27VLjxo2VL18+vfzyywoICNDBgwe1ceNG275t2rSpJOny5csaMWKEqlWrpvz588vLy0utWrXS3r177Z57w4YNslgsWrp0qV5//XWVLFlS7u7uat68uY4dO5Yu77Zt2/T444/Lx8dHHh4eql69uqZPn2435vDhw3ryySdVsGBBubu7q3bt2lq5cqXdmJSUFEVGRiowMFDu7u4qVKiQHnnkEa1fv/6u/j8BAJwHR7wBAA+kq1ev6uLFi3bbChcuLEn64IMP1KtXL4WGhuq///2vrl+/rlmzZumRRx7R7t27FRAQIElav369Tpw4obCwMPn5+engwYOaM2eODh48qK1bt8pisahDhw46cuSIPv74Y02dOtX2M4oUKaILFy5kO3enTp0UGBioiRMnymq1SpJef/11jRkzRp07d1a/fv104cIFvfXWW2rcuLF27959T6e3p6amqlWrVmrcuLEmT56sjz76SIMGDZKHh4deeeUV9ejRQx06dNDs2bPVs2dP1a9fP92p+4MGDVKBAgX06quv6scff9SsWbN0+vRpW9GVbn2gEBkZqZCQEA0cONA2bseOHdq0aZPy5Mlje75Lly6pVatW6tq1q5566ikVLVpUTZs21eDBg5U/f3698sorkqSiRYtKkk6cOKHly5erU6dOKlOmjM6dO6d33nlHTZo00Q8//KDixYvb5Z00aZJcXFw0YsQIXb16VZMnT1aPHj20bds225j169frP//5j4oVK6ahQ4fKz89Phw4d0hdffKGhQ4dKkg4ePKiGDRuqRIkSGjlypDw8PLR06VK1a9dOn376qdq3b2977VFRUerXr5/q1q2rxMRE7dy5U3FxcXrsscey/f8MAJCDWQEAeIDMmzfPKinDm9Vqtf7222/WAgUKWPv372/3uISEBKu3t7fd9uvXr6d7/o8//tgqyfrtt9/atr3xxhtWSdaTJ0/ajT158qRVknXevHnpnkeSddy4cbbvx40bZ5Vk7datm924U6dOWXPlymV9/fXX7bbv37/fmjt37nTbM9sfO3bssG3r1auXVZJ14sSJtm2//vqrNW/evFaLxWJdvHixbfvhw4fTZb39nLVq1bImJyfbtk+ePNkqybpixQqr1Wq1nj9/3urq6mpt0aKFNTU11TYuJibGKsk6d+5c27YmTZpYJVlnz56d7jVUqVLF2qRJk3Tb//jjD7vntVpv7XM3Nzfr+PHjbdu++eYbqyRrpUqVrDdu3LBtnz59ulWSdf/+/Var1Wq9efOmtUyZMtbSpUtbf/31V7vnTUtLs33dvHlza7Vq1ax//PGH3f0NGjSwBgYG2rYFBQVZW7dunS43AAB/xanmAIAH0syZM7V+/Xq7m3TriOaVK1fUrVs3Xbx40XbLlSuX6tWrp2+++cb2HHnz5rV9/ccff+jixYt6+OGHJUlxcXGG5H722Wftvv/f//6ntLQ0de7c2S6vn5+fAgMD7fJmV79+/WxfFyhQQBUqVJCHh4c6d+5s216hQgUVKFBAJ06cSPf4AQMG2B2xHjhwoHLnzq3Vq1dLkr766islJydr2LBhcnH58y1F//795eXlpVWrVtk9n5ubm8LCwu46v5ubm+15U1NTdenSJeXPn18VKlTI8P9PWFiYXF1dbd83atRIkmyvbffu3Tp58qSGDRuW7iyC20fwL1++rK+//lqdO3fWb7/9Zvv/cenSJYWGhuro0aP6+eefJd3apwcPHtTRo0fv+jUBAJwTp5oDAB5IdevWzXBytdslqFmzZhk+zsvLy/b15cuXFRkZqcWLF+v8+fN2465evfovpv3TX0/nPnr0qKxWqwIDAzMcf2fxzQ53d3cVKVLEbpu3t7dKlixpK5l3bs/o2u2/ZsqfP7+KFSumU6dOSZJOnz4t6VZ5v5Orq6vKli1ru/+2EiVK2BXjv5OWlqbp06fr7bff1smTJ5Wammq7r1ChQunGlypVyu57Hx8fSbK9tuPHj0vKevb7Y8eOyWq1asyYMRozZkyGY86fP68SJUpo/Pjxatu2rR566CFVrVpVLVu21NNPP63q1avf9WsEADgHijcAIEdJS0uTdOs6bz8/v3T358795z99nTt31ubNmxUREaHg4GDlz59faWlpatmype15svLXAnvbnQXxr+48yn47r8Vi0ZdffqlcuXKlG58/f/6/zZGRjJ4rq+3W/7/e3Eh/fe1/Z+LEiRozZoz69OmjCRMmqGDBgnJxcdGwYcMy/P/zb7y22887YsQIhYaGZjimfPnykqTGjRvr+PHjWrFihdatW6f33ntPU6dO1ezZs+3ONgAAgOINAMhRypUrJ0ny9fVVSEhIpuN+/fVXxcbGKjIyUmPHjrVtz+i04cwK9u0jqn+dwfuvR3r/Lq/ValWZMmX00EMP3fXj7oejR4/q0UcftX1/7do1nT17Vo8//rgkqXTp0pKkH3/8UWXLlrWNS05O1smTJ7Pc/3fKbP8uW7ZMjz76qN5//3277VeuXLFNcpcdt/9sHDhwINNst19Hnjx57ip/wYIFFRYWprCwMF27dk2NGzfWq6++SvEGANjhGm8AQI4SGhoqLy8vTZw4USkpKenuvz0T+e2jo389Gjpt2rR0j7m91vZfC7aXl5cKFy6sb7/91m7722+/fdd5O3TooFy5cikyMjJdFqvVare02f02Z84cu304a9Ys3bx5U61atZIkhYSEyNXVVTNmzLDL/v777+vq1atq3br1Xf0cDw+PdPtWuvX/6K/75JNPPrFdY51dNWvWVJkyZTRt2rR0P+/2z/H19VXTpk31zjvv6OzZs+me486Z7P/6/yZ//vwqX768bty4cU/5AAA5F0e8AQA5ipeXl2bNmqWnn35aNWvWVNeuXVWkSBHFx8dr1apVatiwoWJiYuTl5WVbaislJUUlSpTQunXrdPLkyXTPWatWLUnSK6+8oq5duypPnjx64okn5OHhoX79+mnSpEnq16+fateurW+//VZHjhy567zlypXTa6+9plGjRunUqVNq166dPD09dfLkSX322WcaMGCARowY8a/tn+xITk5W8+bN1blzZ/344496++239cgjj6hNmzaSbi2pNmrUKEVGRqply5Zq06aNbVydOnX01FNP3dXPqVWrlmbNmqXXXntN5cuXl6+vr5o1a6b//Oc/Gj9+vMLCwtSgQQPt379fH330kd3R9exwcXHRrFmz9MQTTyg4OFhhYWEqVqyYDh8+rIMHD2rt2rWSbk3c98gjj6hatWrq37+/ypYtq3PnzmnLli366aefbOuIV65cWU2bNlWtWrVUsGBB7dy5U8uWLdOgQYPuKR8AIOeieAMAcpzu3burePHimjRpkt544w3duHFDJUqUUKNGjexm1V60aJEGDx6smTNnymq1qkWLFvryyy/TrQ9dp04dTZgwQbNnz9aaNWuUlpamkydPysPDQ2PHjtWFCxe0bNkyLV26VK1atdKXX34pX1/fu847cuRIPfTQQ5o6daoiIyMlSf7+/mrRooWt5JohJiZGH330kcaOHauUlBR169ZNM2bMsDs1/NVXX1WRIkUUExOj4cOHq2DBghowYIAmTpx41xPDjR07VqdPn9bkyZP122+/qUmTJmrWrJlefvllJSUladGiRVqyZIlq1qypVatWaeTIkff8mkJDQ/XNN98oMjJSU6ZMUVpamsqVK6f+/fvbxlSuXFk7d+5UZGSk5s+fr0uXLsnX11c1atSwuyxhyJAhWrlypdatW6cbN26odOnSeu211xQREXHP+QAAOZPFej9mUwEAAA+M+fPnKywsTDt27Mhw5ngAAJA9XOMNAAAAAICBKN4AAAAAABiI4g0AAAAAgIG4xhsAAAAAAANxxBsAAAAAAANRvAEAAAAAMFCOWcc7LS1Nv/zyizw9Pe3WFwUAAAAA4N9mtVr122+/qXjx4nJxyfqYdo4p3r/88ov8/f3NjgEAAAAAcCJnzpxRyZIlsxyTY4q3p6enpFsv2svLy+Q0AAAAAICcLDExUf7+/rYumpUcU7xvn17u5eVF8QYAAAAA3Bd3c6kzk6sBAAAAAGAgijcAAAAAAAaieAMAAAAAYCCKNwAAAAAABqJ4AwAAAABgIIo3AAAAAAAGongDAAAAAGAgijcAAAAAAAa6p+I9c+ZMBQQEyN3dXfXq1dP27dszHXvw4EF17NhRAQEBslgsmjZtWobjfv75Zz311FMqVKiQ8ubNq2rVqmnnzp33Eg8AAAAAAIeR7eK9ZMkShYeHa9y4cYqLi1NQUJBCQ0N1/vz5DMdfv35dZcuW1aRJk+Tn55fhmF9//VUNGzZUnjx59OWXX+qHH37QlClT5OPjk914AAAAAAA4FIvVarVm5wH16tVTnTp1FBMTI0lKS0uTv7+/Bg8erJEjR2b52ICAAA0bNkzDhg2z2z5y5Eht2rRJ3333XfbS3yExMVHe3t66evWqvLy87vl5AAAAAAD4O9npoNk64p2cnKxdu3YpJCTkzydwcVFISIi2bNlyb2klrVy5UrVr11anTp3k6+urGjVq6N13383yMTdu3FBiYqLdDQAAAAAAR5Ot4n3x4kWlpqaqaNGidtuLFi2qhISEew5x4sQJzZo1S4GBgVq7dq0GDhyoIUOGaMGCBZk+JioqSt7e3rabv7//Pf98AAAAAACM4hCzmqelpalmzZqaOHGiatSooQEDBqh///6aPXt2po8ZNWqUrl69arudOXPmPiYGAAAAAODuZKt4Fy5cWLly5dK5c+fstp87dy7TidPuRrFixVS5cmW7bZUqVVJ8fHymj3Fzc5OXl5fdDQAAAAAAR5Ot4u3q6qpatWopNjbWti0tLU2xsbGqX7/+PYdo2LChfvzxR7ttR44cUenSpe/5OQEAAAAAcAS5s/uA8PBw9erVS7Vr11bdunU1bdo0JSUlKSwsTJLUs2dPlShRQlFRUZJuTcj2ww8/2L7++eeftWfPHuXPn1/ly5eXJA0fPlwNGjTQxIkT1blzZ23fvl1z5szRnDlz/q3XCQAAAACAKbK9nJgkxcTE6I033lBCQoKCg4M1Y8YM1atXT5LUtGlTBQQEaP78+ZKkU6dOqUyZMumeo0mTJtqwYYPt+y+++EKjRo3S0aNHVaZMGYWHh6t///53nelBWk4sYOQqsyMY7tSk1mZHAAAAAADDZKeD3lPxdkQUb8dC8QYAAACQkxm2jjcAAAAAAMgeijcAAAAAAAaieAMAAAAAYCCKNwAAAAAABqJ4AwAAAABgIIo3AAAAAAAGongDAAAAAGAgijcAAAAAAAaieAMAAAAAYCCKNwAAAAAABqJ4AwAAAABgIIo3AAAAAAAGongDAAAAAGAgijcAAAAAAAaieAMAAAAAYCCKNwAAAAAABqJ4AwAAAABgIIo3AAAAAAAGongDAAAAAGAgijcAAAAAAAaieAMAAAAAYCCKNwAAAAAABqJ4AwAAAABgIIo3AAAAAAAGongDAAAAAGAgijcAAAAAAAaieAMAAAAAYCCKNwAAAAAABqJ4AwAAAABgIIo3AAAAAAAGongDAAAAAGAgijcAAAAAAAaieAMAAAAAYCCKNwAAAAAABqJ4AwAAAABgIIo3AAAAAAAGongDAAAAAGAgijcAAAAAAAa6p+I9c+ZMBQQEyN3dXfXq1dP27dszHXvw4EF17NhRAQEBslgsmjZtWpbPPWnSJFksFg0bNuxeogEAAAAA4FCyXbyXLFmi8PBwjRs3TnFxcQoKClJoaKjOnz+f4fjr16+rbNmymjRpkvz8/LJ87h07duidd95R9erVsxsLAAAAAACHlO3iHR0drf79+yssLEyVK1fW7NmzlS9fPs2dOzfD8XXq1NEbb7yhrl27ys3NLdPnvXbtmnr06KF3331XPj4+2Y0FAAAAAIBDylbxTk5O1q5duxQSEvLnE7i4KCQkRFu2bPlHQZ5//nm1bt3a7rmzcuPGDSUmJtrdAAAAAABwNNkq3hcvXlRqaqqKFi1qt71o0aJKSEi45xCLFy9WXFycoqKi7voxUVFR8vb2tt38/f3v+ecDAAAAAGAU02c1P3PmjIYOHaqPPvpI7u7ud/24UaNG6erVq7bbmTNnDEwJAAAAAMC9yZ2dwYULF1auXLl07tw5u+3nzp3724nTMrNr1y6dP39eNWvWtG1LTU3Vt99+q5iYGN24cUO5cuVK9zg3N7csrxkHAAAAAMARZOuIt6urq2rVqqXY2FjbtrS0NMXGxqp+/fr3FKB58+bav3+/9uzZY7vVrl1bPXr00J49ezIs3QAAAAAAPCiydcRbksLDw9WrVy/Vrl1bdevW1bRp05SUlKSwsDBJUs+ePVWiRAnb9drJycn64YcfbF///PPP2rNnj/Lnz6/y5cvL09NTVatWtfsZHh4eKlSoULrtAAAAAAA8aLJdvLt06aILFy5o7NixSkhIUHBwsNasWWObcC0+Pl4uLn8eSP/ll19Uo0YN2/dvvvmm3nzzTTVp0kQbNmz4568AAAAAAAAHZrFarVazQ/wbEhMT5e3tratXr8rLy8vsOFkKGLnK7AiGOzWptdkRAAAAAMAw2emgps9qDgAAAABATkbxBgAAAADAQBRvAAAAAAAMRPEGAAAAAMBAFG8AAAAAAAxE8QYAAAAAwEAUbwAAAAAADETxBgAAAADAQBRvAAAAAAAMRPEGAAAAAMBAFG8AAAAAAAxE8QYAAAAAwEAUbwAAAAAADETxBgAAAADAQBRvAAAAAAAMRPEGAAAAAMBAFG8AAAAAAAxE8QYAAAAAwEAUbwAAAAAADETxBgAAAADAQBRvAAAAAAAMRPEGAAAAAMBAFG8AAAAAAAxE8QYAAAAAwEAUbwAAAAAADETxBgAAAADAQBRvAAAAAAAMRPEGAAAAAMBAFG8AAAAAAAxE8QYAAAAAwEAUbwAAAAAADETxBgAAAADAQBRvAAAAAAAMRPEGAAAAAMBAFG8AAAAAAAxE8QYAAAAAwEAUbwAAAAAADETxBgAAAADAQPdUvGfOnKmAgAC5u7urXr162r59e6ZjDx48qI4dOyogIEAWi0XTpk1LNyYqKkp16tSRp6enfH191a5dO/3444/3Eg0AAAAAAIeS7eK9ZMkShYeHa9y4cYqLi1NQUJBCQ0N1/vz5DMdfv35dZcuW1aRJk+Tn55fhmI0bN+r555/X1q1btX79eqWkpKhFixZKSkrKbjwAAAAAAByKxWq1WrPzgHr16qlOnTqKiYmRJKWlpcnf31+DBw/WyJEjs3xsQECAhg0bpmHDhmU57sKFC/L19dXGjRvVuHHju8qVmJgob29vXb16VV5eXnf1GLMEjFxldgTDnZrU2uwIAAAAAGCY7HTQbB3xTk5O1q5duxQSEvLnE7i4KCQkRFu2bLm3tBm4evWqJKlgwYKZjrlx44YSExPtbgAAAAAAOJpsFe+LFy8qNTVVRYsWtdtetGhRJSQk/CuB0tLSNGzYMDVs2FBVq1bNdFxUVJS8vb1tN39//3/l5wMAAAAA8G9yuFnNn3/+eR04cECLFy/OctyoUaN09epV2+3MmTP3KSEAAAAAAHcvd3YGFy5cWLly5dK5c+fstp87dy7TidOyY9CgQfriiy/07bffqmTJklmOdXNzk5ub2z/+mQAAAAAAGClbR7xdXV1Vq1YtxcbG2ralpaUpNjZW9evXv+cQVqtVgwYN0meffaavv/5aZcqUuefnAgAAAADAkWTriLckhYeHq1evXqpdu7bq1q2radOmKSkpSWFhYZKknj17qkSJEoqKipJ0a0K2H374wfb1zz//rD179ih//vwqX768pFunly9atEgrVqyQp6en7Xpxb29v5c2b9195oQAAAAAAmCHbxbtLly66cOGCxo4dq4SEBAUHB2vNmjW2Cdfi4+Pl4vLngfRffvlFNWrUsH3/5ptv6s0331STJk20YcMGSdKsWbMkSU2bNrX7WfPmzVPv3r2zGxEAAAAAAIeR7XW8HRXreDsW1vEGAAAAkJMZto43AAAAAADIHoo3AAAAAAAGongDAAAAAGAgijcAAAAAAAaieAMAAAAAYCCKNwAAAAAABqJ4AwAAAABgIIo3AAAAAAAGongDAAAAAGAgijcAAAAAAAaieAMAAAAAYCCKNwAAAAAABqJ4AwAAAABgIIo3AAAAAAAGongDAAAAAGAgijcAAAAAAAaieAMAAAAAYCCKNwAAAAAABqJ4AwAAAABgIIo3AAAAAAAGongDAAAAAGAgijcAAAAAAAaieAMAAAAAYCCKNwAAAAAABqJ4AwAAAABgIIo3AAAAAAAGongDAAAAAGAgijcAAAAAAAaieAMAAAAAYKDcZgcA7hQwcpXZEe6LU5Namx0BAAAAwH3CEW8AAAAAAAxE8QYAAAAAwEAUbwAAAAAADETxBgAAAADAQBRvAAAAAAAMxKzmwAPEGWZ9Z8Z3AAAA5DQc8QYAAAAAwEAUbwAAAAAADHRPxXvmzJkKCAiQu7u76tWrp+3bt2c69uDBg+rYsaMCAgJksVg0bdq0f/ycAAAAAAA8KLJdvJcsWaLw8HCNGzdOcXFxCgoKUmhoqM6fP5/h+OvXr6ts2bKaNGmS/Pz8/pXnBAAAAADgQZHt4h0dHa3+/fsrLCxMlStX1uzZs5UvXz7NnTs3w/F16tTRG2+8oa5du8rNze1feU4AAAAAAB4U2SreycnJ2rVrl0JCQv58AhcXhYSEaMuWLfcU4F6f88aNG0pMTLS7AQAAAADgaLJVvC9evKjU1FQVLVrUbnvRokWVkJBwTwHu9TmjoqLk7e1tu/n7+9/TzwcAAAAAwEgP7Kzmo0aN0tWrV223M2fOmB0JAAAAAIB0cmdncOHChZUrVy6dO3fObvu5c+cynTjNqOd0c3PL9JpxAAAAAAAcRbaOeLu6uqpWrVqKjY21bUtLS1NsbKzq169/TwGMeE4AAAAAABxFto54S1J4eLh69eql2rVrq27dupo2bZqSkpIUFhYmSerZs6dKlCihqKgoSbcmT/vhhx9sX//888/as2eP8ufPr/Lly9/VcwIAAAAA8KDKdvHu0qWLLly4oLFjxyohIUHBwcFas2aNbXK0+Ph4ubj8eSD9l19+UY0aNWzfv/nmm3rzzTfVpEkTbdiw4a6eEwAAAACAB1W2i7ckDRo0SIMGDcrwvttl+raAgABZrdZ/9JwAAAAAADyoHthZzQEAAAAAeBBQvAEAAAAAMBDFGwAAAAAAA1G8AQAAAAAwEMUbAAAAAAADUbwBAAAAADAQxRsAAAAAAANRvAEAAAAAMBDFGwAAAAAAA1G8AQAAAAAwEMUbAAAAAAADUbwBAAAAADAQxRsAAAAAAANRvAEAAAAAMBDFGwAAAAAAA1G8AQAAAAAwEMUbAAAAAAADUbwBAAAAADAQxRsAAAAAAANRvAEAAAAAMBDFGwAAAAAAA1G8AQAAAAAwEMUbAAAAAAADUbwBAAAAADBQbrMDAMC/JWDkKrMjGO7UpNZmRwAAAEA2ccQbAAAAAAADccQbAJyAM5wNIHFGAAAAcEwc8QYAAAAAwEAUbwAAAAAADETxBgAAAADAQBRvAAAAAAAMRPEGAAAAAMBAzGoOAHB6zjDrOzO+AwBgHo54AwAAAABgIIo3AAAAAAAGongDAAAAAGAgijcAAAAAAAaieAMAAAAAYKB7Kt4zZ85UQECA3N3dVa9ePW3fvj3L8Z988okqVqwod3d3VatWTatXr7a7/9q1axo0aJBKliypvHnzqnLlypo9e/a9RAMAAAAAwKFku3gvWbJE4eHhGjdunOLi4hQUFKTQ0FCdP38+w/GbN29Wt27d1LdvX+3evVvt2rVTu3btdODAAduY8PBwrVmzRh9++KEOHTqkYcOGadCgQVq5cuW9vzIAAAAAABxAtot3dHS0+vfvr7CwMNuR6Xz58mnu3LkZjp8+fbpatmypiIgIVapUSRMmTFDNmjUVExNjG7N582b16tVLTZs2VUBAgAYMGKCgoKC/PZIOAAAAAICjy1bxTk5O1q5duxQSEvLnE7i4KCQkRFu2bMnwMVu2bLEbL0mhoaF24xs0aKCVK1fq559/ltVq1TfffKMjR46oRYsW2YkHAAAAAIDDyZ2dwRcvXlRqaqqKFi1qt71o0aI6fPhwho9JSEjIcHxCQoLt+7feeksDBgxQyZIllTt3brm4uOjdd99V48aNM81y48YN3bhxw/Z9YmJidl4KAAAAAAD3hUPMav7WW29p69atWrlypXbt2qUpU6bo+eef11dffZXpY6KiouTt7W27+fv738fEAAAAAADcnWwd8S5cuLBy5cqlc+fO2W0/d+6c/Pz8MnyMn59fluN///13vfzyy/rss8/UunVrSVL16tW1Z88evfnmm+lOU79t1KhRCg8Pt32fmJhI+QYAAAAAOJxsHfF2dXVVrVq1FBsba9uWlpam2NhY1a9fP8PH1K9f3268JK1fv942PiUlRSkpKXJxsY+SK1cupaWlZZrFzc1NXl5edjcAAAAAABxNto54S7eW/urVq5dq166tunXratq0aUpKSlJYWJgkqWfPnipRooSioqIkSUOHDlWTJk00ZcoUtW7dWosXL9bOnTs1Z84cSZKXl5eaNGmiiIgI5c2bV6VLl9bGjRu1cOFCRUdH/4svFQAAAACA+y/bxbtLly66cOGCxo4dq4SEBAUHB2vNmjW2CdTi4+Ptjl43aNBAixYt0ujRo/Xyyy8rMDBQy5cvV9WqVW1jFi9erFGjRqlHjx66fPmySpcurddff13PPvvsv/ASAQDAvQoYucrsCPfFqUmtzY4AAMjBsl28JWnQoEEaNGhQhvdt2LAh3bZOnTqpU6dOmT6fn5+f5s2bdy9RAAAAAABwaA4xqzkAAAAAADkVxRsAAAAAAANRvAEAAAAAMBDFGwAAAAAAA1G8AQAAAAAw0D3Nag4AAADnWG6NpdYA4J+jeAMAAMAQfDABALdwqjkAAAAAAAaieAMAAAAAYCCKNwAAAAAABqJ4AwAAAABgIIo3AAAAAAAGongDAAAAAGAgijcAAAAAAAaieAMAAAAAYCCKNwAAAAAABqJ4AwAAAABgIIo3AAAAAAAGongDAAAAAGCg3GYHAAAAAJxNwMhVZke4L05Nam12BMAhULwBAAAAOBRn+GCCDyWcC6eaAwAAAABgIIo3AAAAAAAGongDAAAAAGAgijcAAAAAAAaieAMAAAAAYCCKNwAAAAAABqJ4AwAAAABgIIo3AAAAAAAGongDAAAAAGAgijcAAAAAAAaieAMAAAAAYCCKNwAAAAAABqJ4AwAAAABgIIo3AAAAAAAGongDAAAAAGAgijcAAAAAAAaieAMAAAAAYKB7Kt4zZ85UQECA3N3dVa9ePW3fvj3L8Z988okqVqwod3d3VatWTatXr0435tChQ2rTpo28vb3l4eGhOnXqKD4+/l7iAQAAAADgMLJdvJcsWaLw8HCNGzdOcXFxCgoKUmhoqM6fP5/h+M2bN6tbt27q27evdu/erXbt2qldu3Y6cOCAbczx48f1yCOPqGLFitqwYYP27dunMWPGyN3d/d5fGQAAAAAADiDbxTs6Olr9+/dXWFiYKleurNmzZytfvnyaO3duhuOnT5+uli1bKiIiQpUqVdKECRNUs2ZNxcTE2Ma88sorevzxxzV58mTVqFFD5cqVU5s2beTr63vvrwwAAAAAAAeQreKdnJysXbt2KSQk5M8ncHFRSEiItmzZkuFjtmzZYjdekkJDQ23j09LStGrVKj300EMKDQ2Vr6+v6tWrp+XLl2fzpQAAAAAA4HiyVbwvXryo1NRUFS1a1G570aJFlZCQkOFjEhISshx//vx5Xbt2TZMmTVLLli21bt06tW/fXh06dNDGjRszzXLjxg0lJiba3QAAAAAAcDS5zQ6QlpYmSWrbtq2GDx8uSQoODtbmzZs1e/ZsNWnSJMPHRUVFKTIy8r7lBAAAAADgXmTriHfhwoWVK1cunTt3zm77uXPn5Ofnl+Fj/Pz8shxfuHBh5c6dW5UrV7YbU6lSpSxnNR81apSuXr1qu505cyY7LwUAAAAAgPsiW8Xb1dVVtWrVUmxsrG1bWlqaYmNjVb9+/QwfU79+fbvxkrR+/XrbeFdXV9WpU0c//vij3ZgjR46odOnSmWZxc3OTl5eX3Q0AAAAAAEeT7VPNw8PD1atXL9WuXVt169bVtGnTlJSUpLCwMElSz549VaJECUVFRUmShg4dqiZNmmjKlClq3bq1Fi9erJ07d2rOnDm254yIiFCXLl3UuHFjPfroo1qzZo0+//xzbdiw4d95lQAAAAAAmCTbxbtLly66cOGCxo4dq4SEBAUHB2vNmjW2CdTi4+Pl4vLngfQGDRpo0aJFGj16tF5++WUFBgZq+fLlqlq1qm1M+/btNXv2bEVFRWnIkCGqUKGCPv30Uz3yyCP/wksEAAAAAMA89zS52qBBgzRo0KAM78voKHWnTp3UqVOnLJ+zT58+6tOnz73EAQAAAADAYWXrGm8AAAAAAJA9FG8AAAAAAAxE8QYAAAAAwEAUbwAAAAAADETxBgAAAADAQBRvAAAAAAAMRPEGAAAAAMBAFG8AAAAAAAxE8QYAAAAAwEAUbwAAAAAADETxBgAAAADAQBRvAAAAAAAMRPEGAAAAAMBAFG8AAAAAAAxE8QYAAAAAwEAUbwAAAAAADETxBgAAAADAQBRvAAAAAAAMRPEGAAAAAMBAFG8AAAAAAAxE8QYAAAAAwEAUbwAAAAAADETxBgAAAADAQBRvAAAAAAAMRPEGAAAAAMBAFG8AAAAAAAxE8QYAAAAAwEAUbwAAAAAADETxBgAAAADAQBRvAAAAAAAMRPEGAAAAAMBAFG8AAAAAAAxE8QYAAAAAwEAUbwAAAAAADETxBgAAAADAQBRvAAAAAAAMRPEGAAAAAMBAFG8AAAAAAAx0T8V75syZCggIkLu7u+rVq6ft27dnOf6TTz5RxYoV5e7urmrVqmn16tWZjn322WdlsVg0bdq0e4kGAAAAAIBDyXbxXrJkicLDwzVu3DjFxcUpKChIoaGhOn/+fIbjN2/erG7duqlv377avXu32rVrp3bt2unAgQPpxn722WfaunWrihcvnv1XAgAAAACAA8p28Y6Ojlb//v0VFhamypUra/bs2cqXL5/mzp2b4fjp06erZcuWioiIUKVKlTRhwgTVrFlTMTExduN+/vlnDR48WB999JHy5Mlzb68GAAAAAAAHk63inZycrF27dikkJOTPJ3BxUUhIiLZs2ZLhY7Zs2WI3XpJCQ0Ptxqelpenpp59WRESEqlSpkp1IAAAAAAA4tNzZGXzx4kWlpqaqaNGidtuLFi2qw4cPZ/iYhISEDMcnJCTYvv/vf/+r3Llza8iQIXed5caNG7px44bt+8TExLt+LAAAAAAA94vps5rv2rVL06dP1/z582WxWO76cVFRUfL29rbd/P39DUwJAAAAAMC9yVbxLly4sHLlyqVz587ZbT937pz8/PwyfIyfn1+W47/77judP39epUqVUu7cuZU7d26dPn1aL7zwggICAjLNMmrUKF29etV2O3PmTHZeCgAAAAAA90W2irerq6tq1aql2NhY27a0tDTFxsaqfv36GT6mfv36duMlaf369bbxTz/9tPbt26c9e/bYbsWLF1dERITWrl2baRY3Nzd5eXnZ3QAAAAAAcDTZusZbksLDw9WrVy/Vrl1bdevW1bRp05SUlKSwsDBJUs+ePVWiRAlFRUVJkoYOHaomTZpoypQpat26tRYvXqydO3dqzpw5kqRChQqpUKFCdj8jT5488vPzU4UKFf7p6wMAAAAAwFTZLt5dunTRhQsXNHbsWCUkJCg4OFhr1qyxTaAWHx8vF5c/D6Q3aNBAixYt0ujRo/Xyyy8rMDBQy5cvV9WqVf+9VwEAAAAAgIPKdvGWpEGDBmnQoEEZ3rdhw4Z02zp16qROnTrd9fOfOnXqXmIBAAAAAOBwTJ/VHAAAAACAnIziDQAAAACAgSjeAAAAAAAYiOINAAAAAICBKN4AAAAAABiI4g0AAAAAgIEo3gAAAAAAGIjiDQAAAACAgSjeAAAAAAAYiOINAAAAAICBKN4AAAAAABiI4g0AAAAAgIEo3gAAAAAAGIjiDQAAAACAgSjeAAAAAAAYiOINAAAAAICBKN4AAAAAABiI4g0AAAAAgIEo3gAAAAAAGIjiDQAAAACAgSjeAAAAAAAYiOINAAAAAICBKN4AAAAAABiI4g0AAAAAgIEo3gAAAAAAGIjiDQAAAACAgSjeAAAAAAAYiOINAAAAAICBKN4AAAAAABiI4g0AAAAAgIEo3gAAAAAAGIjiDQAAAACAgSjeAAAAAAAYiOINAAAAAICBKN4AAAAAABiI4g0AAAAAgIEo3gAAAAAAGIjiDQAAAACAge6peM+cOVMBAQFyd3dXvXr1tH379izHf/LJJ6pYsaLc3d1VrVo1rV692nZfSkqKXnrpJVWrVk0eHh4qXry4evbsqV9++eVeogEAAAAA4FCyXbyXLFmi8PBwjRs3TnFxcQoKClJoaKjOnz+f4fjNmzerW7du6tu3r3bv3q127dqpXbt2OnDggCTp+vXriouL05gxYxQXF6f//e9/+vHHH9WmTZt/9soAAAAAAHAA2S7e0dHR6t+/v8LCwlS5cmXNnj1b+fLl09y5czMcP336dLVs2VIRERGqVKmSJkyYoJo1ayomJkaS5O3trfXr16tz586qUKGCHn74YcXExGjXrl2Kj4//Z68OAAAAAACTZat4Jycna9euXQoJCfnzCVxcFBISoi1btmT4mC1bttiNl6TQ0NBMx0vS1atXZbFYVKBAgezEAwAAAADA4eTOzuCLFy8qNTVVRYsWtdtetGhRHT58OMPHJCQkZDg+ISEhw/F//PGHXnrpJXXr1k1eXl6ZZrlx44Zu3Lhh+z4xMfFuXwYAAAAAAPeNQ81qnpKSos6dO8tqtWrWrFlZjo2KipK3t7ft5u/vf59SAgAAAABw97JVvAsXLqxcuXLp3LlzdtvPnTsnPz+/DB/j5+d3V+Nvl+7Tp09r/fr1WR7tlqRRo0bp6tWrttuZM2ey81IAAAAAALgvslW8XV1dVatWLcXGxtq2paWlKTY2VvXr18/wMfXr17cbL0nr16+3G3+7dB89elRfffWVChUq9LdZ3Nzc5OXlZXcDAAAAAMDRZOsab0kKDw9Xr169VLt2bdWtW1fTpk1TUlKSwsLCJEk9e/ZUiRIlFBUVJUkaOnSomjRpoilTpqh169ZavHixdu7cqTlz5ki6VbqffPJJxcXF6YsvvlBqaqrt+u+CBQvK1dX133qtAAAAAADcd9ku3l26dNGFCxc0duxYJSQkKDg4WGvWrLFNoBYfHy8Xlz8PpDdo0ECLFi3S6NGj9fLLLyswMFDLly9X1apVJUk///yzVq5cKUkKDg62+1nffPONmjZteo8vDQAAAAAA82W7eEvSoEGDNGjQoAzv27BhQ7ptnTp1UqdOnTIcHxAQIKvVei8xAAAAAABweA41qzkAAAAAADkNxRsAAAAAAANRvAEAAAAAMBDFGwAAAAAAA1G8AQAAAAAwEMUbAAAAAAADUbwBAAAAADAQxRsAAAAAAANRvAEAAAAAMBDFGwAAAAAAA1G8AQAAAAAwEMUbAAAAAAADUbwBAAAAADAQxRsAAAAAAANRvAEAAAAAMBDFGwAAAAAAA1G8AQAAAAAwEMUbAAAAAAADUbwBAAAAADAQxRsAAAAAAANRvAEAAAAAMBDFGwAAAAAAA1G8AQAAAAAwEMUbAAAAAAADUbwBAAAAADAQxRsAAAAAAANRvAEAAAAAMFBuswMAAAAAAO5OwMhVZke4L05Nam12hH8VR7wBAAAAADAQxRsAAAAAAANRvAEAAAAAMBDFGwAAAAAAA1G8AQAAAAAwEMUbAAAAAAADUbwBAAAAADAQxRsAAAAAAANRvAEAAAAAMBDFGwAAAAAAA91T8Z45c6YCAgLk7u6uevXqafv27VmO/+STT1SxYkW5u7urWrVqWr16td39VqtVY8eOVbFixZQ3b16FhITo6NGj9xINAAAAAACHku3ivWTJEoWHh2vcuHGKi4tTUFCQQkNDdf78+QzHb968Wd26dVPfvn21e/dutWvXTu3atdOBAwdsYyZPnqwZM2Zo9uzZ2rZtmzw8PBQaGqo//vjj3l8ZAAAAAAAOINvFOzo6Wv3791dYWJgqV66s2bNnK1++fJo7d26G46dPn66WLVsqIiJClSpV0oQJE1SzZk3FxMRIunW0e9q0aRo9erTatm2r6tWra+HChfrll1+0fPnyf/TiAAAAAAAwW7aKd3Jysnbt2qWQkJA/n8DFRSEhIdqyZUuGj9myZYvdeEkKDQ21jT958qQSEhLsxnh7e6tevXqZPicAAAAAAA+K3NkZfPHiRaWmpqpo0aJ224sWLarDhw9n+JiEhIQMxyckJNjuv70tszEZuXHjhm7cuGH7/urVq5KkxMTEu3w15km7cd3sCIa71/8PzrBvJPZPVv7J32H2T+acYd9I7J+ssG+yxv7JHL+Xs8afnayxfzLHvsnag9Drbme0Wq1/OzZbxduRREVFKTIyMt12f39/E9Lgr7ynmZ3AsbF/Mse+yRr7J2vsn8yxb7LG/skc+yZr7J+ssX8yx77J2oO0f3777Td5e3tnOSZbxbtw4cLKlSuXzp07Z7f93Llz8vPzy/Axfn5+WY6//d9z586pWLFidmOCg4MzzTJq1CiFh4fbvk9LS9Ply5dVqFAhWSyW7LysHC0xMVH+/v46c+aMvLy8zI7jcNg/WWP/ZI59kzX2T+bYN1lj/2SN/ZM59k3W2D9ZY/9kjn2TOavVqt9++03Fixf/27HZKt6urq6qVauWYmNj1a5dO0m3Cm9sbKwGDRqU4WPq16+v2NhYDRs2zLZt/fr1ql+/viSpTJky8vPzU2xsrK1oJyYmatu2bRo4cGCmWdzc3OTm5ma3rUCBAtl5OU7Fy8uLvyhZYP9kjf2TOfZN1tg/mWPfZI39kzX2T+bYN1lj/2SN/ZM59k3G/u5I923ZPtU8PDxcvXr1Uu3atVW3bl1NmzZNSUlJCgsLkyT17NlTJUqUUFRUlCRp6NChatKkiaZMmaLWrVtr8eLF2rlzp+bMmSNJslgsGjZsmF577TUFBgaqTJkyGjNmjIoXL24r9wAAAAAAPKiyXby7dOmiCxcuaOzYsUpISFBwcLDWrFljmxwtPj5eLi5/TpbeoEEDLVq0SKNHj9bLL7+swMBALV++XFWrVrWNefHFF5WUlKQBAwboypUreuSRR7RmzRq5u7v/Cy8RAAAAAADz3NPkaoMGDcr01PINGzak29apUyd16tQp0+ezWCwaP368xo8ffy9xkAU3NzeNGzcu3Wn5uIX9kzX2T+bYN1lj/2SOfZM19k/W2D+ZY99kjf2TNfZP5tg3/w6L9W7mPgcAAAAAAPfE5e+HAAAAAACAe0XxBgAAAADAQBRvAAAAAAAMRPEGAADAAyUlJUV9+vTRyZMnzY4CAHeFydUA2MybN09dunRRvnz5zI4C5CjHjx/XvHnzdPz4cU2fPl2+vr768ssvVapUKVWpUsXsePfdypUr73psmzZtDEyCB5m3t7f27NmjMmXKmB3FoSUnJ+vkyZMqV66ccue+pwWNcqRx48apT58+Kl26tNlR4CQo3jnEjBkz7nrskCFDDEzi+L755hs9+uijZsdwSEWLFtXvv/+uTp06qW/fvmrQoIHZkRzK77//LqvVavtg4vTp0/rss89UuXJltWjRwuR0jic1NVX79+9X6dKl5ePjY3Yc02zcuFGtWrVSw4YN9e233+rQoUMqW7asJk2apJ07d2rZsmVmR7zvXFzsT7izWCy68+2IxWKxfZ2amnrfcuHB0qtXLwUHB2v48OFmR3FI169f1+DBg7VgwQJJ0pEjR1S2bFkNHjxYJUqU0MiRI01OaK7g4GAdOHBATZo0Ud++fdWxY0eWy/p/KSkpyps3r/bs2aOqVauaHSfHoHjnEHf7aa/FYtGJEycMTuPY3NzcVLJkSYWFhalXr17y9/c3O5LDuHnzpj7//HPNnz9fX375pcqWLWvbT35+fmbHM12LFi3UoUMHPfvss7py5YoqVqyoPHny6OLFi4qOjtbAgQPNjmiqYcOGqVq1aurbt69SU1PVpEkTbd68Wfny5dMXX3yhpk2bmh3RFPXr11enTp0UHh4uT09P7d27V2XLltX27dvVoUMH/fTTT2ZHNNVXX32ll156SRMnTlT9+vUlSVu2bNHo0aM1ceJEPfbYYyYnhKN67bXXNGXKFDVv3ly1atWSh4eH3f3OfqBh6NCh2rRpk6ZNm6aWLVtq3759Klu2rFasWKFXX31Vu3fvNjui6Xbv3q158+bp448/1s2bN9W1a1f16dNHderUMTua6cqWLavPPvtMQUFBZkfJOayAk7lw4YI1OjraGhQUZM2dO7e1RYsW1iVLllhv3LhhdjSHkpCQYH3zzTet1apVs+bJk8f6xBNPWJcvX25NTU01O5ppChUqZD1w4IDVarVa3333XWv16tWtqamp1qVLl1orVqxocjrzlShRwrpjxw6r1Wq1fvbZZ9bixYtbf/zxR+vo0aOtDRo0MDmdeTw8PKwnTpywWq1Wa/78+a3Hjx+3Wq1W68mTJ61ubm5mRnMIVapUsX733Xfptn/77bdO//eqQIECVh8fn7+9OauAgIBMb2XKlDE7nulKlSpl3bJli9Vqtf/dc/ToUaunp6eZ0RxOcnKy9dNPP7X+5z//sebJk8darVo167Rp06xXrlwxO5pp3nvvPevjjz9uvXTpktlRcgwu9MjhrP9/QsOdp+05u8KFC2v48OEaPny44uLiNG/ePD333HN67rnn1L17d/Xt25dP93TrtPNHHnlER44c0ZEjR7R//3716tVLPj4+mjdvnlMevbx+/bo8PT0lSevWrVOHDh3k4uKihx9+WKdPnzY5nfkuXrxoOzNi9erV6tSpkx566CH16dNH06dPNzmdeQoUKKCzZ8+mOzNp9+7dKlGihEmpHMfx48dVoECBdNu9vb116tSp+57HkUybNs32tdVq1cCBAzV+/Hj5+vqaF8qBMLFa1i5cuJDhn5WkpCTeF/6F1WpVSkqKkpOTZbVa5ePjo5iYGI0ZM0bvvvuuunTpYnbE+y4mJkbHjh1T8eLFVbp06XRnlMTFxZmU7MFF8c6hFi5cqDfeeENHjx6VJD300EOKiIjQ008/bXIyx1KzZk35+fmpUKFCmjRpkubOnau3335b9evX1+zZs51y0qNz587pgw8+0Lx583TixAm1a9dOX3zxhUJCQpSUlKTx48erV69eTlk0y5cvr+XLl6t9+/Zau3at7brC8+fPy8vLy+R05itatKh++OEHFStWTGvWrNGsWbMk3frAIleuXCanM0/Xrl310ksv6ZNPPpHFYlFaWpo2bdqkESNGqGfPnmbHM12dOnUUHh6uDz74QEWLFpV06/dQRESE6tata3I6c/Xq1cvu+8GDB6tjx44qW7asSYnwIKldu7ZWrVqlwYMHS/rzIMx7771nu6zD2e3atct2qrmbm5t69uypmTNnqnz58pKkt956S0OGDHHK4t2uXTuzI+Q85h5whxGmTJlizZcvn/XFF1+0rlixwrpixQprRESENV++fNbo6Giz4zmE5ORk6yeffGJt1aqVNXfu3NaHH37Y+u6771qvXbtmPXnypLVHjx7WSpUqmR3zvrt9ilWVKlWsU6dOzfD0onPnzlktFosJ6cz3ySefWPPkyWN1cXGxhoSE2LZPnDjR2rJlSxOTOYZx48ZZvb29rRUrVrSWKlXK+scff1itVqv1/ffftz788MMmpzPPjRs3rP369bPmzp3barFYbH+GnnrqKevNmzfNjme6o0ePWqtWrWp1dXW1litXzlquXDmrq6urtUqVKtajR4+aHc+h3Hm6MG45c+aMdebMmdaXXnrJOnz4cLubs/vuu++s+fPntz777LNWd3d369ChQ62PPfaY1cPDw7pz506z45muatWq1ty5c1sff/xx62effZbh7+MLFy447Xse/PuYXC0HKlOmjCIjI9MdSVmwYIFeffVVpz81a/Dgwfr4449ltVr19NNPq1+/fulmbExISFDx4sWVlpZmUkpz9O3bV/369cvyk3Cr1ar4+HinXX4jISFBZ8+eVVBQkG1m5u3bt8vLy0sVK1Y0OZ35li1bpjNnzqhTp04qWbKkpFu/ewoUKKC2bduanM5c8fHxOnDggK5du6YaNWooMDDQ7EgOw2q1av369Tp8+LAkqVKlSgoJCeF02L+4c3I+SLGxsWrTpo3Kli2rw4cPq2rVqjp16pSsVqtq1qypr7/+2uyIpjt+/LgmTZqkvXv36tq1a6pZs6ZeeuklVatWzexoppswYYL69OnDJT+4byjeOZC7u7sOHDhgO03mtqNHj6patWr6448/TErmGJo3b65+/fqpQ4cOmS4bcfPmTW3atElNmjS5z+nMtXDhQnXp0iXdfklOTtbixYs5Lfb/HTt2TMePH1fjxo2VN29eWa1WCsJf/PHHH3J3dzc7BpCjULzt1a1bV61atVJkZKRt3/j6+qpHjx5q2bKl0680gayNHz9eI0aMsC0Retvvv/+uN954Q2PHjjUpmWNwcXHJ8r0NSz1mH8U7B6pataq6d++ul19+2W77a6+9piVLlmj//v0mJXMM3377rRo0aKDcue2nOLh586Y2b96sxo0bm5TMfLly5dLZs2fTTcZy6dIl+fr6Ov0v2UuXLqlz58765ptvZLFYdPToUZUtW1Z9+vSRj4+PpkyZYnZEU6WmpmrixImaPXu2zp07Z1szdsyYMQoICFDfvn3NjnjfhIeH3/XY6OhoA5M4phkzZmjAgAFyd3fXjBkzshzrzEtC/fXP0cyZM/XUU0/J29vbbrsz/hmSbn0QsWfPHpUrV04+Pj76/vvvVaVKFe3du1dt27Z1ysn5EhMT73qss89NwnuerK1YscLu+5SUFO3evVsLFixQZGSkU/2b/m9hcrUcKDIyUl26dNG3336rhg0bSpI2bdqk2NhYLV261OR05nv00Ucz/EV79epVPfroo079izazI7c//fRTujd6zmj48OHKkyeP4uPjValSJdv2Ll26KDw83OmL9+uvv64FCxZo8uTJ6t+/v2171apVNW3aNKf6R/qv6+PGxcXp5s2bqlChgiTpyJEjypUrl2rVqmVGPNNNnTpVPXr0kLu7u6ZOnZrpOIvF4tTF+69/jho0aKATJ07YbXPms208PDyUnJwsSSpWrJiOHz9umxT14sWLZkYzTYECBe76z4Qzv9+RMn/Ps3fvXhUsWNCERI4lo8vDnnzySVWpUkVLlixxqn/T/y0U7xyoY8eO2rZtm6ZOnarly5dLunW93Pbt21WjRg1zwzmAzH7RXrp0Kd1SCc6iRo0aslgsslgsat68ud3ZAKmpqTp58qRatmxpYkLHsG7dOq1du9Z27fJtgYGBTjnL+18tXLhQc+bMUfPmzfXss8/atgcFBdmu3XUW33zzje3r6OhoeXp6asGCBfLx8ZEk/frrrwoLC1OjRo3MimiqO+cacfZ5R7Jy55+j26wsE2rz8MMP6/vvv1elSpX0+OOP64UXXtD+/fv1v//9Tw8//LDZ8Uxx55+ZU6dOaeTIkerdu7dt7pYtW7ZowYIFioqKMiui6Xx8fGzveR566CG7v0upqam6du2a3b9hsPfwww9rwIABZsd4IFG8c6hatWrpww8/NDuGQ+nQoYOkW29WevfubXcdc2pqqvbt26cGDRqYFc9Ut5eM2LNnj0JDQ5U/f37bfa6urgoICFDHjh1NSuc4kpKS0l0LJkmXL1/OdL4AZ/Lzzz+nm1tCktLS0pSSkmJCIscwZcoUrVu3zla6pVtv/F577TW1aNFCL7zwgonp8KB4//33NXXqVNsyoYGBgRo2bJj69etncjLzREdH69q1a5June137do1LVmyRIGBgU57+v2dc9OMHz9e0dHR6tatm21bmzZtVK1aNc2ZMyfdcnXOYtq0abJarerTp48iIyPtzui7/Z6H5dYy9vvvv2vGjBlMSHePKN45VFpamo4dO6bz58+nm5nbWa9hvv2L1Wq1ytPTU3nz5rXd5+rqqocfftju9FhnMm7cOElSQECAunTpwqRYmWjUqJEWLlyoCRMmSJJtTebJkyfr0UcfNTmd+SpXrqzvvvsu3Yz3y5Ytc+qzbRITE3XhwoV02y9cuKDffvvNhESOpWPHjqpbt65eeuklu+2TJ0/Wjh079Mknn5iUzHGMHTtW0dHRGjx4sN2Ry+HDhys+Pl7jx483OaE57pxkzsPDQ7NnzzYxjePZsmVLhvukdu3aTv2Bze0PHMqUKaMGDRooT548JidyTLfPDLjNarXqt99+U758+Ti4d4+YXC0H2rp1q7p3767Tp0/rr/97LRaL01/TExkZqREjRjjtaeW4dwcOHFDz5s1ty9S0adNGBw8e1OXLl7Vp0yaVK1fO7IimWrFihXr16qVRo0Zp/PjxioyM1I8//qiFCxfqiy++0GOPPWZ2RFP07NlT3333naZMmaK6detKkrZt26aIiAg1atRICxYsMDmhuYoUKaKvv/463fJG+/fvV0hIiM6dO2dSMsdRpEgRzZgxw+7IpSR9/PHHGjx4sNNez4ysVahQQW3bttXkyZPttr/44otasWKFfvzxR5OSmScxMdE2qdzfTUTn7JPP/fXfJhcXFxUpUkT16tWzO4MLd4/inQMFBwfroYceUmRkpIoVK5buOjAmycKdChYsqCNHjqhw4cLpPt38q8uXL9/HZI7p6tWriomJsVsT9fnnn1exYsXMjuYQvvvuO40fP95u/4wdO1YtWrQwO5pprl+/rhEjRmju3Lm2U+5z586tvn376o033nD6DwHz5s2rPXv22Caeu+3w4cOqUaOGfv/9d5OSOY4CBQpox44d6dZ+P3LkiOrWrasrV66YE8xkmf2bZbFY5O7urvLly6t3794KCwszIZ35Vq9erY4dO6p8+fKqV6+eJGn79u06evSoPv30Uz3++OMmJ7z/7pzJPLPlsm7PBeTsB6rw76N450AeHh7au3dvhtdaOquaNWsqNjZWPj4+tonEMhMXF3cfk5lvwYIF6tq1q9zc3DR//vws942zXg92W3x8vPz9/TPcR/Hx8SpVqpQJqfCgSEpK0vHjxyVJ5cqVc/rCfVvdunX1n//8J92aua+++qo+//xz7dq1y6RkjmPw4MHKkydPuuuWR4wYod9//10zZ840KZm5pk6dqtdff12tWrWynU2yfft2rVmzRsOHD9fJkyf1wQcf6K233nLaS8nOnDmjWbNm2Sa4rFSpkp599ln5+/ubnMwcGzduVMOGDZU7d25t3Lgxy7F3Xi/vrK5cuaL3339fhw4dkiRVqVJFffr04SDePaJ450DNmjXTiy++yCzUd4iMjFRERITy5cunyMjILMfevt4Z+CvW/AT+fZ9//rk6dOig7t27q1mzZpKk2NhYffzxx/rkk09skz86s8GDB2vhwoXy9/e3zda9bds2xcfHq2fPnnbXqDrTpGIdO3bUY489lm4G6nfeeUfr1q3Tp59+qrfeektz5szR/v37TUoJPJh27typ0NBQ5c2b1/bB1o4dO/T7779r3bp1qlmzpskJHzwU7xxi3759tq+PHz+u0aNHKyIiQtWqVUs3aUT16tXvdzw4sL+7xulOzn69k4uLi86dO6ciRYrYbT99+rQqV66spKQkk5KZ5+8uT7iTM12q0KFDB82fP19eXl62FRUy87///e8+pXJcq1at0sSJE7Vnzx7lzZtX1atX17hx4zji9P/udvJGi8Wir7/+2uA0jiN//vzas2dPujP8jh07puDgYF27dk3Hjx9X9erVneb38759+1S1alW5uLjYvTfMiDO+H/y7fXInZ9w/d2rUqJHKly+vd99917bM7M2bN9WvXz+dOHFC3377rckJHzzMap5DBAcHy2Kx2E2m1qdPH9vXt+/jmpVbp11ZLBbbWszbt2/XokWLVLlyZadcl7BAgQJ3XZyc9c9OeHi4pFt/j8aMGWO3pFhqaqq2bdum4OBgk9KZa9q0abavL126pNdee02hoaF2My+vXbtWY8aMMSmhOby9vW1/rzgl7++1bt1arVu3NjuGw8poPW/cmqPk888/1/Dhw+22f/755ypYsKCkW5d4eHp6mhHPFMHBwUpISJCvr2+G7w1vc9b3g3fuk7977+OM++dOO3futCvd0q35SV588UXVrl3bxGQPLop3DnHy5EmzIzwwunfvrgEDBujpp59WQkKCQkJCVLVqVX300UdKSEhId51hTnfnG7pTp05p5MiR6t27t11xWrBggaKiosyKaLrdu3dLujXhyv79++Xq6mq7z9XVVUFBQRoxYoRZ8Ux153X/HTt21Pjx4zVo0CDbtiFDhigmJkZfffVVujfHOdm8efMy/BrAv2fMmDEaOHCgvvnmG7tTYVevXm1bRmv9+vVOdebEyZMnbWdl8d4wvTv3ye7duzVixAhFRETYveeZMmVKupngnZGXl5fi4+NVsWJFu+1nzpxxqg+z/k2cag6n4+Pjo61bt6pChQqaMWOGlixZok2bNmndunV69tlndeLECbMjmqZ58+bq169fuiVrFi1apDlz5mjDhg3mBHMQYWFhmj59utOfcp+Zuznt0xkdPnw43RuX29auXavQ0ND7nMixpKamaurUqVq6dKni4+OVnJxsd78zXaKA7Nu0aZNiYmJsS2NVqFBBgwcPVoMGDUxO5tju5ohvTle3bl29+uqr6WZ3X716tcaMGeP0EzsOGTJEn332md58803b36dNmzYpIiJCHTt2tDvjDXfHxewAMMbx48c1ePBghYSEKCQkREOGDLHNpuvsUlJS5ObmJkn66quv1KZNG0lSxYoVdfbsWTOjmW7Lli0Znj5Uu3Ztbd++3YREjmXevHmU7iwUKlRIK1asSLd9xYoVKlSokAmJHEPNmjXTzTp948YNDRo0SG3btjUpleOIjIxUdHS0unTpoqtXryo8PFwdOnSQi4uLXn31VbPjwcE1bNhQH3/8seLi4hQXF6ePP/6Y0v3/evfuneG17adOnVLjxo1NSORY9u/frzJlyqTbXqZMGf3www8mJHIsb775pjp06KCePXsqICBAAQEB6t27t5588kn997//NTveA4kj3jnQ2rVr1aZNGwUHB6thw4aSbn1CtXfvXn3++ed67LHHTE5ornr16unRRx9V69at1aJFC23dulVBQUHaunWrnnzySf30009mRzRNhQoV1LZt23SnWL344otasWKF7YiCM9u5c2emR+acfZKs+fPnq1+/fmrVqpVtzdht27ZpzZo1evfdd9W7d29zA5pk6dKlGjhwoOrVq6d58+bp7Nmz6t69u9LS0vTBBx+oTp06Zkc0Vbly5TRjxgy1bt1anp6e2rNnj23b1q1btWjRIrMjwkHFx8dneb+zL/FYo0YNJSYm6sMPP7SdSr1gwQINGTJEzZo102effWZyQnPVrFlTVatW1XvvvWe7hCw5OVn9+vXTgQMHnG552cxcv37dbinMO+e5QfZQvHOgGjVqKDQ0VJMmTbLbPnLkSK1bt87pf5Fs2LBB7du3V2Jionr16qW5c+dKkl5++WUdPnzYqcvT6tWr1bFjR5UvX95WnLZv366jR4/q008/TXc6lrNZvHixevbsqdDQUK1bt04tWrTQkSNHdO7cObVv355reXWraM+YMcO25melSpU0ZMgQ258nZ/XTTz8pLCxMu3fvVlJSknr37q0pU6bwBkaSh4eHDh06pFKlSqlYsWJatWqVatasqRMnTqhGjRq6evWq2RHhoFxcXLI8XdrZJ8dKSUnRyy+/rBkzZuiFF17QsWPH9OWXXyo6Otpp1zW/0/bt2/XEE0/IarXaZjDft2+fLBaLPv/8c9u8AcC/hcnVcqBDhw5p6dKl6bb36dOH6zEkNW3aVBcvXlRiYqJ8fHxs2wcMGOD0b4Iff/xxHTlyRLNmzdLhw4clSU888YSeffZZ+fv7m5zOfBMnTtTUqVP1/PPPy9PTU9OnT1eZMmX0zDPPqFixYmbHcwj16tXTRx99ZHYMh5ScnKzU1FSlpqaqWLFicnd3NzuSQyhZsqTOnj2rUqVKqVy5crb1YXfs2GG7LAjIyO2JL29LSUnR7t27FR0drddff92kVI4jT548euONN5QvXz5NmDBBuXPn1saNG21Hv51d3bp1deLECX300Ue29zxdunRR9+7d5eHhYXI6c/zd8pd3cuYDVfeK4p0DFSlSRHv27FFgYKDd9j179sjX19ekVI4lV65cdqVbkgICAswJ42D8/f01ceJEs2M4pOPHj9uWPHJ1dVVSUpIsFouGDx+uZs2aKTIy0uSE919iYqLtuve/WxPeWa+PX7x4sQYOHKhGjRrpyJEj2rNnj8LCwrR27Vp98MEHKlu2rNkRTdW+fXvFxsaqXr16Gjx4sJ566im9//77io+Pd6qZ8JF9QUFB6bbVrl1bxYsX1xtvvJGtEpETpaSkaOTIkZo5c6ZGjRql77//Xh06dND777/v9Gew3ebh4eGUS8lmhuUvjUXxzoH69++vAQMG6MSJE3azEP73v/+1rUfszM6dO6cRI0YoNjZW58+fT7e+pbOdmrZv3z5VrVpVLi4u2rdvX5Zjb5+K5ax8fHz022+/SZJKlCihAwcOqFq1arpy5YquX79ucjpz+Pj46OzZs/L19c10Tfjbs+c629+t2/r27as333xTAwcOlCQ99thj2rdvn5599lkFBwf/7QcWOd2dl0V16dJFpUuX1ubNmxUYGKgnnnjCxGR4UFWoUEE7duwwO4bpateurevXr2vDhg16+OGHZbVaNXnyZHXo0EF9+vTR22+/bXbE+27lypVq1aqV8uTJo5UrV2Y59vbku86ES+aMxTXeOZDVatW0adM0ZcoU/fLLL5Kk4sWLKyIiQkOGDHH65SNatWql+Ph4DRo0SMWKFUu3P5xtlmEXFxclJCTI19fXdr1cRr8WnLk43da9e3fVrl1b4eHhmjBhgt566y21bdtW69evV82aNZ3ytKuNGzeqYcOGtlMYs+JMa+ne6ccff1SFChUyvO+DDz7Q008/fZ8TATnDXz+0slqtOnv2rF599VUdPnxYe/bsMSeYg+jbt69mzJiR7rTp3bt36+mnn9aBAwdMSmaev77nyQzvef504cIFu+X6bq8Tj+yjeOdwt4/OsdD9nzw9PfXdd98pODjY7CgO4fTp0ypVqpQsFotOnz6d5djSpUvfp1SO6fLly/rjjz9UvHhxpaWlafLkybYjc6NHj053+YIzuXnzpiZOnKg+ffqoZMmSZsdxSLt27bJNOle5cmXVrFnT5ETAgy2jydWsVqv8/f21ePFirmXOwo0bN5hDAVlKSkrS4MGDtXDhQqWlpUm6dalmz5499dZbbzn9vEj3guKdA508eVI3b95Md4330aNHlSdPHqe/lrly5cr66KOPVKNGDbOjADmKp6en9u/f7/S/Y/7q/Pnz6tq1qzZs2KACBQpIkq5cuaJHH31Uixcv5ugBcI/+epaNi4uLihQpovLlyyt3bq6mlG7tozfffNPuQ7+IiAg1atTI5GRwdM8884y++uorxcTE2JYn/v777zVkyBA99thjmjVrlskJHzwU7xyoSZMm6tOnj3r16mW3/cMPP9R7772nDRs2mBPMQaxbt05TpkzRO++8Q0H4i6ioKBUtWlR9+vSx2z537lxduHBBL730kknJHEdaWpqOHTum8+fP2z4Bvq1x48YmpXIMbdu2VYcOHdL97nF2Xbp00YkTJ7Rw4UJVqlRJkvTDDz+oV69eKl++vD7++GOTEwLIiT788EOFhYWpQ4cOtuK0adMmffbZZ5o/f766d+9uckJzDRkyROXLl9eQIUPstsfExOjYsWNOvxJQ4cKFtWzZMjVt2tRu+zfffKPOnTvrwoUL5gR7gFG8cyAvLy/FxcWpfPnydtuPHTum2rVr68qVK+YEcxA+Pj66fv26bt68qXz58ilPnjx291++fNmkZOYLCAjQokWLbJPy3bZt2zZ17dpVJ0+eNCmZY9i6dau6d++u06dPp7sOnuvBpNmzZysyMlI9evRQrVq10l1X6IwT1Ui3Zon96quvVKdOHbvt27dvV4sWLZz+dzJwrxYsWKDChQvbVpt48cUXNWfOHFWuXFkff/yx018eValSJQ0YMCDd6gDR0dF69913bUfBnVWJEiW0cuVK1apVy257XFyc2rRpo59++smkZI4hX7582rVrl+0D49sOHjyounXrKikpyaRkDy7Ow8mBLBaL7druO129etXpi4Ekp/8EMysJCQkZrkddpEgRnT171oREjuXZZ59V7dq1tWrVqgwn5nN2zz33nKRbb+r+ypk/mEhLS0v3AZ90a43dv5414Yx27NihtLQ01atXz277tm3blCtXLtWuXdukZHB0EydOtJ3uumXLFsXExGjatGn64osvNHz4cKec8PJOJ06cyHBlgDZt2ujll182IZFjuXTpUobLZ3l5eenixYsmJHIs9evX17hx47Rw4UK5u7tLkn7//XdFRkYyf8I9onjnQI0bN1ZUVJQ+/vhj5cqVS9KtJbKioqL0yCOPmJzOfJwGmzl/f39t2rRJZcqUsdu+adMmFS9e3KRUjuPo0aNatmxZurNJcAslMmPNmjXT0KFD9fHHH9v+Hv38888aPny4mjdvbnI68z3//PN68cUX0xXvn3/+Wf/973+1bds2k5LB0Z05c8b2+3j58uV68sknNWDAADVs2DDd6bHOyN/fX7Gxsen+zfrqq6/k7+9vUirHUb58ea1Zs0aDBg2y2/7ll1+qbNmyJqVyHNOmTVPLli1VsmRJBQUFSZL27t0rNzc3rVu3zuR0DyaKdw703//+V40bN1aFChVsk2d89913SkxM1Ndff21yOsdw/PhxzZs3T8ePH9f06dPl6+urL7/8UqVKlVKVKlXMjmea/v37a9iwYUpJSVGzZs0kSbGxsXrxxRf1wgsvmJzOfPXq1dOxY8co3siWmJgYtWnTRgEBAbY3u2fOnFHVqlX14YcfmpzOfD/88EOGM7zXqFFDP/zwgwmJ8KDInz+/Ll26pFKlSmndunUKDw+XJLm7u+v33383OZ35XnjhBQ0ZMkR79uyxXUK2adMmzZ8/X9OnTzc5nfnCw8M1aNAgXbhwwe49z5QpUzg7UlK1atV09OhRffTRRzp8+LAkqVu3burRo4fy5s1rcroHE8U7B6pcubL27dunmJgY7d27V3nz5lXPnj01aNAgFSxY0Ox4ptu4caNatWqlhg0b6ttvv9Xrr78uX19f7d27V++//76WLVtmdkTTRERE6NKlS3ruueeUnJws6dYbmJdeekmjRo0yOZ059u3bZ/t68ODBeuGFF5SQkKBq1aqlO324evXq9zuew2EG3fT8/f0VFxenr776yvbmpVKlSgoJCTE5mWNwc3PTuXPn0h1hOnv2LDNTI0uPPfaY+vXrpxo1aujIkSN6/PHHJd26BpXJU6WBAwfKz89PU6ZM0dKlSyXd+t2zZMkStW3b1uR05uvTp49u3Lih119/XRMmTJB0a66bWbNmqWfPnianM9/tCXf79+9vt50Jd+8dk6vB6dSvX1+dOnVSeHi4PD09tXfvXpUtW1bbt29Xhw4dnH4yDUm6du2aDh06pLx58yowMNCp1/q8vU5sZr8qb9/nzNcw38YMurgX3bp109mzZ7VixQrb9ZZXrlxRu3bt5OvraysMwF9duXJFo0eP1pkzZzRw4EC1bNlSkjRu3Di5urrqlVdeMTkhHhQXLlxQ3rx5lT9/frOjOAwm3P33UbxziDuPyv0dZz8qlz9/fu3fv19lypSxK96nTp1SxYoV9ccff5gdEQ7k9OnTdz2WGXSZQfe2GTNmaMCAAXJ3d9eMGTOyHPvXpWyczc8//6zGjRvr0qVLqlGjhiRpz549Klq0qNavX8+1qABgAnd3dx06dCjdvD8nTpxQ5cqVeb98DziHK4cIDg7O8qjcbRyVkwoUKKCzZ8+m+0Wye/dulShRwqRUjmPnzp1aunSp4uPjbaeb3+aMM8Q6e5nODmbQ/dPUqVPVo0cPubu7a+rUqZmOs1gsTl+8S5QooX379umjjz6yXR4VFhambt26ZTgbPIDMFSxYUEeOHFHhwoXl4+OT5eobzrx86m3Lli3L9D1PXFycSakcAxPu/vso3jkEp3vcva5du+qll17SJ598IovForS0NG3atEkjRoxw+mt6Fi9erJ49eyo0NFTr1q1TixYtdOTIEZ07d07t27c3O55D+PHHH/XWW2/Zjt5WqlRJgwcPVoUKFUxOZj5m0P3Tnb+T+f389zw8PDRgwACzYwAPvKlTp8rT01MSy6f+nRkzZuiVV15R7969tWLFCoWFhen48ePasWOHnn/+ebPjmY4Jd/99nGqeg/3www/pPsGzWCwZHpFyJsnJyXr++ec1f/58paamKnfu3Lp586Z69Oih+fPn25Zgc0bVq1fXM888o+eff952Gn6ZMmX0zDPPqFixYoqMjDQ7oqk+/fRTde3aVbVr17atYbl161bt2LFDixcvVseOHU1OaK5Zs2Zp2LBh6tOnT4Yz6D7zzDMmJ4SjWLlypVq1aqU8efJo5cqVWY5t06bNfUoFwJlUrFhR48aNU7du3ewuPRw7dqwuX76smJgYsyOaymq1auTIkZoxY0a6CXfHjh1rcroHE8U7Bzpx4oTat2+v/fv3251+fvt0I2c/1fy2M2fOaP/+/bp27Zpq1KihwMBAsyOZzsPDwzYbbKFChbRhwwZVq1ZNhw4dUrNmzXT27FmzI5qqXLly6tGjh8aPH2+3fdy4cfrwww91/Phxk5I5js8++0xTpkyxOyMgIiLC6WbQvb2s0d2Ijo42MIljcnFxUUJCgnx9feXi4pLpOC6PArInMTHxrsd6eXkZmMTx5cuXT4cOHVLp0qXl6+ur9evXKygoSEePHtXDDz+sS5cumR3RITDh7r+HU81zoKFDh6pMmTKKjY1VmTJltG3bNl2+fFkvvPCC3nzzTbPjmeLv3gRv3brV9rUzvgm+zcfHR7/99pukW9ddHjhwQNWqVdOVK1d0/fp1k9OZ7+zZsxlejvDUU0/pjTfeMCGR42nfvj2XJejWnBF3iouL082bN22XJBw5ckS5cuVSrVq1zIhnurS0tAy/BvDPFChQIMvruu/k7B9q+fn56fLlyypdurRKlSqlrVu3KigoSCdPnvzbOZOcSf78+VWnTh2zY+QIFO8caMuWLfr6669VuHBhubi4KFeuXHrkkUcUFRWlIUOGpHtD6Ax4E3x3GjdurPXr16tatWrq1KmThg4dqq+//lrr169X8+bNzY5nuqZNm+q7775Ldw3z999/79TrVCO9b775xvZ1dHS0PD09tWDBAvn4+EiSfv31V4WFhTn9n5uUlBS1bNlSs2fP5qwj3JUaNWrcdbF0xsmx7vzdc+rUKY0cOVK9e/e2XR61ZcsWLViwQFFRUWZFdBjNmjXTypUrVaNGDYWFhWn48OFatmyZdu7cqQ4dOpgdDzkQp5rnQD4+PoqLi1OZMmVUrlw5vffee3r00Ud1/PhxVatWzemPXEZHR2vDhg2Zvgl25gkjLl++rD/++EPFixdXWlqaJk+erM2bNyswMFCjR4+27S9nNXv2bI0dO1adO3fWww8/LOnW2RKffPKJIiMj7Wb5dJbrUv9u1tw7OesMuiVKlNC6detUpUoVu+0HDhxQixYt9Msvv5iUzDEUKVLE9nsG+DvZmWtk3LhxBiZxfM2bN1e/fv3UrVs3u+2LFi3SnDlztGHDBnOCOYi0tDSlpaUpd+5bxyEXL15s+130zDPPyNXV1eSEyGko3jnQ7fLYrl07de/eXb/++qtGjx6tOXPmaNeuXTpw4IDZEU3Fm2Dcq6yuRb2TM12XumDBgrse26tXLwOTOC5PT099/vnnatq0qd32b775Rm3atLFd3uGshg8fLjc3N02aNMnsKECOki9fPu3duzfdh1pHjhxRcHCw0x+IAe43TjXPgUaPHq2kpCRJ0vjx4/Wf//xHjRo1UqFChbRkyRKT05kvMTFRFy5cSLf9woULTv8GGFnjWtT0nLVMZ0f79u0VFhamKVOmqG7dupKkbdu2KSIigtMZJd28eVNz587VV199pVq1asnDw8PufmeedwP4J/z9/fXuu+9q8uTJdtvfe+89p1viEXAEHPF2EpcvX87WKaE5Wc+ePfXdd99l+Ca4UaNG2TqCB8BeWlqajh07pvPnz6f7oKJx48YmpTLX9evXNWLECM2dO1cpKSmSpNy5c6tv375644030hVNZ/Poo49mef+d16wCd0pNTdXUqVO1dOnSdMunSs57ecttq1evVseOHVW+fHnVq1dPkrR9+3YdPXpUn376qR5//HGTEwLOheINp8ObYGTHjBkz7nrskCFDDEzi+LZu3aru3bvr9OnT6WaEdabT7zOTlJRkW3KuXLly/K4B/qGxY8fqvffe0wsvvKDRo0frlVde0alTp7R8+XKNHTvW6X8nS9JPP/2kWbNm2S3x+Oyzz3LEGzABxRtOizfBuBtlypS5q3EWi0UnTpwwOI1jCw4O1kMPPaTIyEgVK1Ys3Rk23t7eJiWDI+vTp4+mT58uT09Pu+1JSUkaPHiw5s6da1IyOLpy5cppxowZat26tTw9PbVnzx7btq1bt2rRokVmRwQAG4o3gHSOHTum48ePq3HjxsqbN6+sViuXKeBveXh4aO/evemWWwOykitXLp09e1a+vr522y9evCg/Pz/dvHnTpGRwdB4eHjp06JBKlSqlYsWKadWqVapZs6ZOnDihGjVq6OrVq2ZHBAAbJlcDYHPp0iV16dJFX3/9tSwWi44ePaqyZcuqb9++8vHx0ZQpU8yOCAdWr149HTt2jOKNu5KYmCir1Sqr1arffvtN7u7utvtSU1O1evXqdGUcuFPJkiV19uxZlSpVSuXKldO6detUs2ZN7dixQ25ubmbHgwNiHXiYieINwGb48OHKnTu34uPjValSJdv2Ll26KDw83OmLd58+fbK83xlPid23b5/t68GDB+uFF15QQkKCqlWrpjx58tiNrV69+v2OBwdWoEABWSwWWSwWPfTQQ+nut1gs2VqzGc6nffv2io2NVb169TR48GA99dRTev/99xUfH6/hw4ebHQ8OqF27drav//jjD7399tuqXLmy6tevL+nWXCUHDx7Uc889Z1JC5GScag7Axs/PT2vXrlVQUJA8PT21d+9elS1bVidOnFD16tV17do1syOaqn379nbfp6Sk6MCBA7py5YqaNWum//3vfyYlM4+Li4ssFku6ydRuu32fs06ulpKSomeeeUZjxoy56/kCnMXGjRtltVrVrFkzffrppypYsKDtPldXV5UuXVrFixc3MSEeNFu2bNGWLVsUGBioJ554wuw4prJarTpz5ox8fX3tzibBn/r166dixYppwoQJdtvHjRunM2fOOOWH6TAWxRuAjaenp+Li4hQYGGhXvHfu3KnQ0FBdunTJ7IgOJy0tTQMHDlS5cuX04osvmh3nvjt9+vRdjy1durSBSRyXt7e39uzZQ/HOxOnTp1WqVCnmkQD+RWlpaXJ3d9fBgwcVGBhodhyH5O3trZ07d6bbP0ePHlXt2rWZIwD/Ok41B2DTqFEjLVy40Pbpr8ViUVpamiZPnvy3a+06KxcXF4WHh6tp06ZOWbzvLNNRUVEqWrRoulPy586dqwsXLuill1663/EcQrt27bR8+XJOfb3Dvn37VLVqVbm4uOjq1avav39/pmO5RAGZWbhwYZb39+zZ8z4lcTwuLi4KDAzUpUuXKN6ZyJs3rzZt2pRu/2zatImzBGAIijcAm8mTJ6t58+bauXOnkpOT9eKLL+rgwYO6fPmyNm3aZHY8h3X8+HFmXpb0zjvvZLh8T5UqVdS1a1enLd6BgYEaP368Nm3apFq1aqVbutAZ1xoODg5WQkKCfH19FRwcnOnlCs56iQLuztChQ+2+T0lJ0fXr1+Xq6qp8+fI5dfGWpEmTJikiIkKzZs1S1apVzY7jcIYNG6aBAwcqLi5OdevWlSRt27ZNc+fO1ZgxY0xOh5yIU80B2Ll69apiYmK0d+9eXbt2TTVr1tTzzz+vYsWKmR3NdOHh4XbfW61WnT17VqtWrVKvXr0UExNjUjLH4O7urkOHDqU7pfrEiROqXLmy/vjjD5OSmSurU8yddf33O08v/7vLFZz1EgXcm6NHj2rgwIGKiIhQaGio2XFM5ePjo+vXr+vmzZtydXVV3rx57e6/fPmySckcx9KlSzV9+nQdOnRIklSpUiUNHTpUnTt3NjkZciKKNwDcpb+ebu/i4qIiRYqoWbNm6tOnj3Lndu6TiAIDAzVu3Dg99dRTdts/+OADjRs3zikLJoD7b+fOnXrqqad0+PBhs6OYasGCBVne36tXr/uUBIDEqeaA07tzOai/4+zXWq5atUpWq9V2qvCpU6e0fPlylS5d2ulLtyT1799fw4YNU0pKipo1ayZJio2N1YsvvqgXXnjB5HRwVMwNgH9b7ty59csvv5gdw3QU67935coVLVu2TCdOnNCIESNUsGBBxcXFqWjRoipRooTZ8ZDDcMQbcHJ/txzUbVxrKbVo0UIdOnTQs88+qytXrqhixYrKkyePLl68qOjoaA0cONDsiKayWq0aOXKkZsyYoeTkZEm3Tj9/6aWXNHbsWJPTmYf137MWEBCgRYsWqUGDBnbbt23bpq5du+rkyZMmJYOjW7lypd33ty//iYmJkb+/v7788kuTkjmG+Pj4LO8vVarUfUrimPbt26eQkBB5e3vr1KlT+vHHH1W2bFmNHj1a8fHxfzt5H5BdFG/AybEc1N0rXLiwNm7cqCpVqui9997TW2+9pd27d+vTTz/V2LFjbdeIObtr167p0KFDyps3rwIDA+Xm5mZ2JFOx/nvWmBsA98rFxcXue4vFYrv8Z8qUKU4/N8ntD9Yz4+wfpoeEhKhmzZqaPHmy3RKqmzdvVvfu3XXq1CmzIyKH4dxIwMk5e5nOjuvXr8vT01OStG7dOnXo0EEuLi56+OGHs/UBRk6XP39+1alTx+wYDuOzzz5Lt+3O9d+dnb+/vzZt2pSueG/atEnFixc3KRUeBGlpaWZHcGi7d++2+z4lJUW7d+9WdHS0Xn/9dZNSOY4dO3bonXfeSbe9RIkSSkhIMCERcjqKN+DkVq5cqVatWilPnjzpTtv7qzZt2tynVI6pfPnyWr58udq3b6+1a9fa1mU+f/68vLy8TE6HB4mzr/9+J+YGAIwRFBSUblvt2rVVvHhxvfHGG+rQoYMJqRyHm5ubEhMT020/cuSIihQpYkIi5HScag44ORcXF9t6un89be9OXOMtLVu2TN27d1dqaqqaN2+udevWSbo1OdS3337r9NcTIntWr16tXr166cKFC2ZHMRVzAyA7/rqsY1aio6MNTPLgOnbsmIKCgpSUlGR2FFP169dPly5d0tKlS1WwYEHt27dPuXLlUrt27dS4cWNNmzbN7IjIYSjeAJANCQkJOnv2rIKCgmwfVGzfvl1eXl6qWLGiyengiFj//e4wNwDuxl+XdYyLi9PNmzdVoUIFSbeOVubKlUu1atXS119/bUZEh/HXo7m3f/e8+uqrOnz4sPbs2WNOMAdx9epVPfnkk9q5c6d+++03FS9eXAkJCapfv75Wr15tW8EE+LdQvAHYLFy4UF26dEn3hjc5OVmLFy9Wz549TUoGPLiaNm1qN8ER678D/47o6Ght2LBBCxYskI+PjyTp119/VVhYmBo1auT0lypkNLma1WqVv7+/Fi9erPr165uUzLFs2rRJe/fu1bVr11SzZk2FhISYHQk5FMUbgE2uXLl09uxZ+fr62m2/dOmSfH19nf5Uc+Bu3Tl3AgBjlChRQuvWrVOVKlXsth84cEAtWrRw+rW8N27caPf97Q/9ypcvzwd+kg4fPpzpmWpr165VaGjofU6EnC7zCzoBOB2r1Zrh0iM//fSTvL29TUgEPJjat2+vK1euSLr1gdb58+fNDQTkQImJiRnOkXDhwgX99ttvJiQyX82aNfXrr79KulW869SpoyZNmqhJkyZq1KiRKlasSOn+fzVr1tTMmTPttt24cUODBg1S27ZtTUqFnIy/eQBUo0YNWSwWWSwWNW/e3O4f5dTUVJ08eVItW7Y0MSHwYClSpIi2bt2qJ554ItMPtAD8M+3bt1dYWJimTJmiunXrSpK2bdumiIgIp52x+9ChQ0pKSpKPj48iIyM1cOBA5cuXz+xYDmn+/PkaOHCgVq1apXnz5uns2bPq3r270tLS9N1335kdDzkQxRuA2rVrJ0nas2ePQkNDlT9/ftt9rq6uCggIUMeOHU1KBzx4nn32WbVt29b2gZafn1+mY7mEA7g3s2fP1ogRI9S9e3elpKRIknLnzq2+ffvqjTfeMDmdOYKDgxUWFqZHHnlEVqtVb7zxht2/6Xdy9lUDOnfurAYNGigsLExVqlRRUlKSevfurSlTpvBhBQzBNd4AbBYsWKAuXbrI3d3d7CjAA+/w4cM6duyY2rRpo3nz5qlAgQIZjuOURuCfSUpK0vHjxyVJ5cqVc+rZqH/88UeNGzdOx48fV1xcnCpXrpzhqeUWi0VxcXEmJHQsP/30k3r06KF9+/YpKSlJo0eP1ujRo7NcXhW4VxRvAAAMFBkZqYiICI6gALivXFxclJCQkG7CVNyyePFiDRw4UI0aNdL777+vPXv2KCwsTKVLl9YHH3ygsmXLmh0ROQzFG4BNamqqpk6dqqVLlyo+Pl7Jycl291++fNmkZAAASB06dND8+fPl5eX1t9dx/+9//7tPqfAg8vDw0JtvvqmBAwfatv3666965plntGbNmnTroAP/FNd4A7CJjIzUe++9pxdeeEGjR4/WK6+8olOnTmn58uVOfy0YkB23Jyy8G5zuCdw9b29v298tVttIb+XKlXc9tk2bNgYmcXxxcXGqUKGC3TYfHx8tXbpUH3zwgUmpkJNxxBuATbly5TRjxgy1bt1anp6e2rNnj23b1q1btWjRIrMjAg+EyMjIux47btw4A5MAcCZ3e22yxWJhYkfgPqN4A7Dx8PDQoUOHVKpUKRUrVkyrVq1SzZo1deLECdWoUUNXr141OyIAAJKk33//XVar1TZ/wunTp/XZZ5+pcuXKatGihcnp4IjCw8M1YcIEeXh4KDw8PMux0dHR9ykVnAWnmgOwKVmypM6ePatSpUqpXLlyWrdunWrWrKkdO3bIzc3N7HgAANi0bdtWHTp00LPPPqsrV66obt26cnV11cWLFxUdHW137S4gSbt377YtPRcXF5fpJUF3e6kQkB0c8QZgM3LkSHl5eenll1/WkiVL9NRTTykgIEDx8fEaPny4Jk2aZHZE4IHj4uKS5Zs4TvcE7k3hwoW1ceNGValSRe+9957eeust7d69W59++qnGjh2rQ4cOmR3RVOPHj8/yfmecu2Xfvn2qWrUqy4XBFBRvAJnasmWLtmzZosDAQD3xxBNmxwEeSCtWrLD7PiUlRbt379aCBQsUGRmpvn37mpQMeLDly5dPhw8fVqlSpdS5c2dVqVJF48aN05kzZ1ShQgVdv37d7IimqlGjht33KSkpOnnypHLnzq1y5co55cSOuXLl0tmzZ+Xr66uyZctqx44dKlSokNmx4CQ41RxApurXr6/69eubHQN4oLVt2zbdtieffFJVqlTRkiVLKN7APSpfvryWL1+u9u3ba+3atRo+fLgk6fz58/Ly8jI5nfl2796dbltiYqJ69+6t9u3bm5DIfAUKFNDJkyfl6+urU6dOKS0tzexIcCIc8QacHEuPAOY4ceKEqlevrmvXrpkdBXggLVu2TN27d1dqaqqaNWum9evXS5KioqL07bff6ssvvzQ5oWPav3+/nnjiCZ06dcrsKPfdgAEDtHDhQhUrVkzx8fEqWbKkcuXKleHYEydO3Od0yOk44g04uXbt2t3VOJYeAf49v//+u2bMmKESJUqYHQV4YD355JN65JFHdPbsWQUFBdm2N2/e3GmP6N6Nq1evOu0qJXPmzFGHDh107NgxDRkyRP3795enp6fZseAkKN6Ak+M0K8BYPj4+dpOrWa1W/fbbb8qXL58+/PBDE5MBDz4/Pz9du3ZN69evV+PGjZU3b17VqVOHWaklzZgxw+57q9Wqs2fP6oMPPlCrVq1MSmW+li1bSpJ27dqloUOHUrxx33CqOQAABpo/f75dCXBxcVGRIkVUr149+fj4mJgMeLBdunRJnTt31jfffCOLxaKjR4+qbNmy6tOnj3x8fDRlyhSzI5qqTJkydt/f/t3TrFkzjRo1isIJ3GcUbwB2Nm7cqDfffNO2DEvlypUVERGhRo0amZwMAIA/9ezZU+fPn9d7772nSpUqae/evSpbtqzWrl2r8PBwHTx40OyIAGDDInYAbD788EOFhIQoX758GjJkiIYMGaK8efOqefPmWrRokdnxgAfSmjVr9P3339u+nzlzpoKDg9W9e3f9+uuvJiYDHmzr1q3Tf//7X5UsWdJue2BgoE6fPm1SKseVmJio5cuXO/365oBZKN4AbF5//XVNnjxZS5YssRXvJUuWaNKkSZowYYLZ8YAHUkREhBITEyXdmk04PDxcjz/+uE6ePKnw8HCT0wEPrqSkJOXLly/d9suXL8vNzc2ERI6lc+fOiomJkXRrQsfatWurc+fOql69uj799FOT0wHOh+INwObEiRN64okn0m1v06aNTp48aUIi4MF38uRJVa5cWZL06aef6oknntDEiRM1c+ZMljsC/oFGjRpp4cKFtu8tFovS0tI0efJkPfrooyYmcwzffvut7TKxzz77TFarVVeuXNGMGTP02muvmZwOcD7Mag7Axt/fX7GxsSpfvrzd9q+++kr+/v4mpQIebK6urrp+/bqkW3+XevbsKUkqWLCg7Ug4gOybPHmymjdvrp07dyo5OVkvvviiDh48qMuXL2vTpk1mxzPd1atXVbBgQUm3Lnnp2LGj8uXLp9atWysiIsLkdIDzoXgDsHnhhRc0ZMgQ7dmzRw0aNJAkbdq0SfPnz9f06dNNTgc8mB555BGFh4erYcOG2r59u5YsWSJJOnLkSLprUwHcvapVq+rIkSOKiYmRp6enrl27pg4dOuj5559XsWLFzI5nOn9/f23ZskUFCxbUmjVrtHjxYknSr7/+Knd3d5PTAc6H4g3AZuDAgfLz89OUKVO0dOlSSVKlSpW0ZMkStW3b1uR0wIMpJiZGzz33nJYtW6ZZs2apRIkSkqQvv/zStp4sgOxJSUlRy5YtNXv2bL3yyitmx3FIw4YNU48ePZQ/f36VLl1aTZs2lXTrFPRq1aqZGw5wQiwnBgAAgAdOkSJFtHnzZgUGBpodxWHt2rVL8fHxeuyxx5Q/f35J0qpVq1SgQAE1bNjQ5HSAc6F4A7Dp16+fnnrqKdun4gAAOKrhw4fLzc1NkyZNMjsKAPwtTjUHYHPhwgW1bNlSRYoUUdeuXdWjRw8FBwebHQsAgHRu3rypuXPn6quvvlKtWrXk4eFhd390dLRJyQAgPY54A7Dz66+/6pNPPtGiRYv03XffqWLFiurRo4e6d++ugIAAs+MBACBJWS4ZZrFY9PXXX9/HNACQNYo3gEz99NNP+vjjjzV37lwdPXpUN2/eNDsSAAAA8MBxMTsAAMeUkpKinTt3atu2bTp16pSKFi1qdiQAAADggcQ13gDsfPPNN1q0aJE+/fRTpaWlqUOHDvriiy/UrFkzs6MBD4wOHTrc9dj//e9/BiYB4My+++47vfPOOzp+/LiWLVumEiVK6IMPPlCZMmX0yCOPmB0PcCoUbwA2JUqU0OXLl9WyZUvNmTNHTzzxhNzc3MyOBTxwvL29zY4AwMl9+umnevrpp9WjRw/t3r1bN27ckCRdvXpVEydO1OrVq01OCDgXrvEGYPPuu++qU6dOKlCggNlRAADAP1CjRg0NHz5cPXv2lKenp/bu3auyZctq9+7datWqlRISEsyOCDgVjngDsOnfv7/ZEQAAwL/gxx9/VOPGjdNt9/b21pUrV+5/IMDJUbwBADDYsmXLtHTpUsXHxys5Odnuvri4OJNSAcjJ/Pz8dOzYsXRLgX7//fcqW7asOaEAJ8as5gAAGGjGjBkKCwtT0aJFtXv3btWtW1eFChXSiRMn1KpVK7PjAcih+vfvr6FDh2rbtm2yWCz65Zdf9NFHH2nEiBEaOHCg2fEAp8M13gAAGKhixYoaN26cunXrZned5dixY3X58mXFxMSYHRFADmS1WjVx4kRFRUXp+vXrkiQ3NzeNGDFCEyZMMDkd4Hwo3gAAGChfvnw6dOiQSpcuLV9fX61fv15BQUE6evSoHn74YV26dMnsiABysOTkZB07dkzXrl1T5cqVlT9/frMjAU6JU80BADCQn5+fLl++LEkqVaqUtm7dKkk6efKk+OwbgNHi4+N15swZVatWTfnz5+f3DmASijcAAAZq1qyZVq5cKUkKCwvT8OHD9dhjj6lLly5q3769yekA5FSXLl1S8+bN9dBDD+nxxx/X2bNnJUl9+/bVCy+8YHI6wPlwqjkAAAZKS0tTWlqacue+tZDI4sWLtXnzZgUGBuqZZ56Rq6uryQkB5EQ9e/bU+fPn9d5776lSpUq2+SXWrl2r8PBwHTx40OyIgFOheAMAYKD4+Hj5+/vLYrHYbbdarTpz5oxKlSplUjIAOZmfn5/Wrl2roKAgu4kdT5w4oerVq+vatWtmRwScCqeaAwBgoDJlyujChQvptl++fFllypQxIREAZ5CUlKR8+fKl23758mW5ubmZkAhwbhRvAAAMZLVa0x3tlqRr167J3d3dhEQAnEGjRo20cOFC2/cWi0VpaWmaPHmyHn30UROTAc4pt9kBAADIicLDwyXderM7ZswYuyNPqamp2rZtm4KDg01KByCnmzx5spo3b66dO3cqOTlZL774og4ePKjLly9r06ZNZscDnA7FGwAAA+zevVvSrSPe+/fvt5tEzdXVVUFBQRoxYoRZ8QDkcFWrVtWRI0cUExMjT09PXbt2TR06dNDzzz+vYsWKmR0PcDpMrgYAgIHCwsI0ffp0eXl5mR0FgJNISUlRy5YtNXv2bAUGBpodB4Ao3gAA3Dc//fSTJKlkyZImJwGQ0xUpUsS2dCEA8zG5GgAABkpLS9P48ePl7e2t0qVLq3Tp0ipQoIAmTJigtLQ0s+MByKGeeuopvf/++2bHAPD/uMYbAAADvfLKK3r//fc1adIkNWzYUJL0/fff69VXX9Uff/yh119/3eSEAHKimzdvau7cufrqq69Uq1YteXh42N0fHR1tUjLAOXGqOQAABipevLhmz56tNm3a2G1fsWKFnnvuOf38888mJQOQk2W1ZJjFYtHXX399H9MA4Ig3AAAGunz5sipWrJhue8WKFXX58mUTEgHIqfbt26eqVavKxcVF33zzjdlxANyBa7wBADBQUFCQYmJi0m2PiYlRUFCQCYkA5FQ1atTQxYsXJUlly5bVpUuXTE4E4DaOeAMAYKDJkyerdevW+uqrr1S/fn1J0pYtW3TmzBmtXr3a5HQAcpICBQro5MmT8vX11alTp5jAEXAgXOMNAIDBfvnlF82cOVOHDx+WJFWqVEnPPfecihcvbnIyADnJgAEDtHDhQhUrVkzx8fEqWbKkcuXKleHYEydO3Od0gHOjeAMAYKD4+Hj5+/vLYrFkeF+pUqVMSAUgp1qzZo2OHTumIUOGaPz48fL09Mxw3NChQ+9zMsC5UbwBADBQrly5dPbsWfn6+tptv3Tpknx9fZWammpSMgA5WVhYmGbMmJFp8QZwf3GNNwAABrJarRke7b527Zrc3d1NSATAGcybN8/sCADuQPEGAMAA4eHhkm6tlztmzBjly5fPdl9qaqq2bdum4OBgk9IBAID7ieINAIABdu/eLenWEe/9+/fL1dXVdp+rq6uCgoI0YsQIs+IBAID7iGu8AQAwUFhYmKZPny4vL6//a78OSgAAgiCGwfkXfSrKwJIo6LfrFABgxHgDAABA6K0DAAAA4DLjDQAAACHjDQAAACHjDQAAACHjDQAAACHjDQAAACHjDQAAACHjDQAAAKEP5mcugr7xGvsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "importances = best_rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "feature_names = US_X_train.columns if hasattr(US_X_train, 'columns') else [f\"f{i}\" for i in range(len(importances))]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.bar(range(len(importances)), importances[indices], align=\"center\")\n",
    "plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
